{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a831aeee-40cb-440b-a2cf-0050de0f16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer import Transformer\n",
    "from datasets import load_dataset\n",
    "#import spacy\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1ad63ab-6a07-4b37-b1b7-49f7136d0735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89dfd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.Tensor([[\"a\"],[\"b\"],[\"c\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1198c574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "english_tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\", padding_side = \"right\", truncation_side = \"right\", model_max_length = 64)\n",
    "german_tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\", padding_side = \"right\", truncation_side = \"right\", model_max_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc84dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Tokenizer Special Tokens: {'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}\n",
      "German Tokenizer Special Tokens: {'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}\n"
     ]
    }
   ],
   "source": [
    "print(\"English Tokenizer Special Tokens:\", english_tokenizer.special_tokens_map)\n",
    "print(\"German Tokenizer Special Tokens:\", german_tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b39015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}\n"
     ]
    }
   ],
   "source": [
    "special_tokens = {\"bos_token\": \"<s>\"}\n",
    "\n",
    "# Add the special token to the tokenizer\n",
    "german_tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# Check the updated special tokens and see if <s> has been added\n",
    "print(german_tokenizer.special_tokens_map)\n",
    "\n",
    "# Get the ID of the newly added <s> token\n",
    "bos_token_id = german_tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "#print(f\"<s> token ID: {bos_token_id}\")\n",
    "\n",
    "# Get the token for ID 2 (which could be <s> or another token)\n",
    "#token_for_id_2 = german_tokenizer.convert_ids_to_tokens(32100)\n",
    "#print(token_for_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cd13d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'additional_special_tokens': ['<extra_id_0>', '<extra_id_1>', '<extra_id_2>', '<extra_id_3>', '<extra_id_4>', '<extra_id_5>', '<extra_id_6>', '<extra_id_7>', '<extra_id_8>', '<extra_id_9>', '<extra_id_10>', '<extra_id_11>', '<extra_id_12>', '<extra_id_13>', '<extra_id_14>', '<extra_id_15>', '<extra_id_16>', '<extra_id_17>', '<extra_id_18>', '<extra_id_19>', '<extra_id_20>', '<extra_id_21>', '<extra_id_22>', '<extra_id_23>', '<extra_id_24>', '<extra_id_25>', '<extra_id_26>', '<extra_id_27>', '<extra_id_28>', '<extra_id_29>', '<extra_id_30>', '<extra_id_31>', '<extra_id_32>', '<extra_id_33>', '<extra_id_34>', '<extra_id_35>', '<extra_id_36>', '<extra_id_37>', '<extra_id_38>', '<extra_id_39>', '<extra_id_40>', '<extra_id_41>', '<extra_id_42>', '<extra_id_43>', '<extra_id_44>', '<extra_id_45>', '<extra_id_46>', '<extra_id_47>', '<extra_id_48>', '<extra_id_49>', '<extra_id_50>', '<extra_id_51>', '<extra_id_52>', '<extra_id_53>', '<extra_id_54>', '<extra_id_55>', '<extra_id_56>', '<extra_id_57>', '<extra_id_58>', '<extra_id_59>', '<extra_id_60>', '<extra_id_61>', '<extra_id_62>', '<extra_id_63>', '<extra_id_64>', '<extra_id_65>', '<extra_id_66>', '<extra_id_67>', '<extra_id_68>', '<extra_id_69>', '<extra_id_70>', '<extra_id_71>', '<extra_id_72>', '<extra_id_73>', '<extra_id_74>', '<extra_id_75>', '<extra_id_76>', '<extra_id_77>', '<extra_id_78>', '<extra_id_79>', '<extra_id_80>', '<extra_id_81>', '<extra_id_82>', '<extra_id_83>', '<extra_id_84>', '<extra_id_85>', '<extra_id_86>', '<extra_id_87>', '<extra_id_88>', '<extra_id_89>', '<extra_id_90>', '<extra_id_91>', '<extra_id_92>', '<extra_id_93>', '<extra_id_94>', '<extra_id_95>', '<extra_id_96>', '<extra_id_97>', '<extra_id_98>', '<extra_id_99>']}\n"
     ]
    }
   ],
   "source": [
    "special_tokens = {\"bos_token\": \"<s>\"}\n",
    "\n",
    "english_tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "print(english_tokenizer.special_tokens_map)\n",
    "\n",
    "\n",
    "bos_token_id = english_tokenizer.convert_tokens_to_ids(\"<s>\")\n",
    "#print(f\"<s> token ID: {bos_token_id}\")\n",
    "\n",
    "#token_for_id_2 = english_tokenizer.convert_ids_to_tokens(32100)\n",
    "#print(token_for_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c47642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> token ID: 32100\n",
      "</s> token ID: 1\n"
     ]
    }
   ],
   "source": [
    "start_token_id = english_tokenizer.convert_tokens_to_ids('<s>')\n",
    "end_token_id = english_tokenizer.convert_tokens_to_ids('</s>')\n",
    "\n",
    "print(f\"<s> token ID: {start_token_id}\")\n",
    "print(f\"</s> token ID: {end_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5860c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> token ID: 32100\n",
      "</s> token ID: 1\n"
     ]
    }
   ],
   "source": [
    "start_token_id = german_tokenizer.convert_tokens_to_ids('<s>')\n",
    "end_token_id = german_tokenizer.convert_tokens_to_ids('</s>')\n",
    "\n",
    "print(f\"<s> token ID: {start_token_id}\")\n",
    "print(f\"</s> token ID: {end_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "426d0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab_dim = english_tokenizer.vocab_size + 1\n",
    "target_vocab_dim = german_tokenizer.vocab_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7574c34-77ef-4f85-b36d-c34935279fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"wmt/wmt14\",\"de-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf5744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a8671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec266a17-7e0f-4132-9605-8776a2c9e5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ff9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83077922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7956a69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Resumption of the session', 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.', \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\", 'You have requested a debate on this subject in the course of the next few days, during this part-session.', \"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\", \"Please rise, then, for this minute' s silence.\", \"(The House rose and observed a minute' s silence)\", 'Madam President, on a point of order.', 'You will be aware from the press and television that there have been a number of bomb explosions and killings in Sri Lanka.', 'One of the people assassinated very recently in Sri Lanka was Mr Kumar Ponnambalam, who had visited the European Parliament just a few months ago.']\n"
     ]
    }
   ],
   "source": [
    "print([x['en'] for x in dataset[\"train\"][:10]['translation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d03e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "    \n",
    "    def __init__(self, dataset, partition):\n",
    "        \n",
    "        \n",
    "        self.dataset = dataset[partition]\n",
    "        self.english_tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\", padding_side = \"right\", truncation_side = \"right\", model_max_length = 64)\n",
    "        self.german_tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-base\", padding_side = \"right\", truncation_side = \"right\", model_max_length = 64)\n",
    "        \n",
    "        if os.path.exists(f\"./SavedData/{partition}\"):\n",
    "            self.english_texts = torch.load(f\"./SavedData/{partition}/en.pth\")\n",
    "            self.german_texts = torch.load(f\"./SavedData/{partition}/de.pth\")\n",
    "        else:\n",
    "            \n",
    "            self.english_texts = [self.applyEnglishTokenizer(sample['en']).unsqueeze(0) for sample in tqdm(self.dataset[:2*10**4]['translation'])]\n",
    "            self.german_texts = [self.applyGermanTokenizer(sample['de']).unsqueeze(0) for sample in tqdm(self.dataset[:2*10**4]['translation'])]\n",
    "            \n",
    "            self.english_texts = torch.cat(self.english_texts)\n",
    "            self.german_texts = torch.cat(self.german_texts)\n",
    "            \n",
    "            print(self.english_texts.shape)\n",
    "            \n",
    "            if not os.path.exists(\"./SavedData\"):\n",
    "                os.mkdir(\"./SavedData\")\n",
    "            if not os.path.exists(f\"./SavedData/{partition}\"):\n",
    "                os.mkdir(f\"./SavedData/{partition}\")\n",
    "            \n",
    "            torch.save(self.english_texts,f\"./SavedData/{partition}/en.pth\")\n",
    "            torch.save(self.german_texts,f\"./SavedData/{partition}/de.pth\")\n",
    "            \n",
    "        \n",
    "    def applyEnglishTokenizer(self, text):\n",
    "        #print(text)\n",
    "        tok = self.english_tokenizer(text, padding = \"max_length\", truncation = \"only_first\", add_special_tokens=True,\n",
    "               return_tensors = \"pt\")['input_ids'].squeeze(0)\n",
    "    \n",
    "        bos_token = torch.Tensor([32100])\n",
    "        tok = torch.cat([bos_token, tok])\n",
    "        \n",
    "        #print(tok.shape)\n",
    "        if tok[-1] == 1:\n",
    "            return torch.cat([tok[:-2], tok[-1:]])\n",
    "        else:\n",
    "            return tok[:-1]\n",
    "            \n",
    "    def applyGermanTokenizer(self, text):\n",
    "        tok = self.german_tokenizer(text, padding = \"max_length\", truncation = \"only_first\", add_special_tokens=True,\n",
    "               return_tensors = \"pt\")['input_ids'].squeeze(0)\n",
    "    \n",
    "        bos_token = torch.Tensor([32100])\n",
    "        tok = torch.cat([bos_token, tok])\n",
    "        \n",
    "        if tok[-1] == 1:\n",
    "            return torch.cat([tok[:-2], tok[-1:]])\n",
    "        else:\n",
    "            return tok[:-1]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.english_texts[idx], self.german_texts[idx]\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.english_texts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e7615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.english_texts = torch.load(f\"./SavedData/{partition}/en.pth\")\n",
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.german_texts = torch.load(f\"./SavedData/{partition}/de.pth\")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DatasetClass(dataset, \"train\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3987cf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.english_texts = torch.load(f\"./SavedData/{partition}/en.pth\")\n",
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.german_texts = torch.load(f\"./SavedData/{partition}/de.pth\")\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = DatasetClass(dataset, \"validation\")\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a14e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size = source_vocab_dim, target_vocab_size = target_vocab_dim, source_seq_len = 64, target_seq_len = 64, embedding_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e297b459-d18a-4865-905f-cb8660fe4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(\"./checkpoints/model_parameters.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "142324ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_vocab_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "011c8de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding_layer): EmbeddingLayer(\n",
       "      (model): Embedding(32101, 64)\n",
       "    )\n",
       "    (positional_embedder): PositionalEncoder()\n",
       "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0-5): 6 x EncoderBlock(\n",
       "        (attention): MultiHeadAttention(\n",
       "          (WQuery): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WKey): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WValue): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WOut): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (firstLayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (secondLayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding_layer): EmbeddingLayer(\n",
       "      (model): Embedding(32101, 64)\n",
       "    )\n",
       "    (positional_embedder): PositionalEncoder()\n",
       "    (fc): Linear(in_features=64, out_features=32101, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (selfAttentionLayer): MultiHeadAttention(\n",
       "          (WQuery): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WKey): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WValue): Linear(in_features=64, out_features=64, bias=False)\n",
       "          (WOut): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (firstLayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (encoderBlock): EncoderBlock(\n",
       "          (attention): MultiHeadAttention(\n",
       "            (WQuery): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (WKey): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (WValue): Linear(in_features=64, out_features=64, bias=False)\n",
       "            (WOut): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "          (firstLayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (secondLayerNorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d79d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_dataset.english_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4863852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr = 1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8a9718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d153f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load('checkpoints/model_parameters.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce3eb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e260bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,  5837,  ...,     0,     0,     0],\n",
      "        [32100,     3, 16239,  ...,     0,     0,     0],\n",
      "        [32100,  2167,  3941,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0],\n",
      "        [32100,  1546, 24425,  ...,     0,     0,     0],\n",
      "        [32100,  7217,    67,  ..., 14866, 11553,     1]], device='cuda:0')\n",
      "tensor([[ 5.3299,  3.8612,  2.0673,  ..., -4.1114, -3.8279, -2.3770],\n",
      "        [ 5.4173,  3.9760,  2.2033,  ..., -3.9610, -3.8659, -2.3999],\n",
      "        [ 5.4777,  3.9295,  2.1098,  ..., -3.7392, -4.0463, -2.6747],\n",
      "        ...,\n",
      "        [ 8.7445,  4.8726,  1.7729,  ..., -4.4071, -3.7502, -3.1834],\n",
      "        [ 8.7429,  4.8774,  1.5977,  ..., -4.4493, -3.7730, -3.2080],\n",
      "        [ 8.5571,  4.9824,  1.8473,  ..., -4.4520, -3.8215, -3.1529]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  316,  5837,  5451,  ..., 11553,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,     3, 17499,  ...,     0,     0,     0],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        [32100,  5837, 11502,  ...,  6184,   218,     1],\n",
      "        ...,\n",
      "        [32100, 11565,     6,  ...,     0,     0,     0],\n",
      "        [32100,  1674,   177,  ...,     0,     0,     0],\n",
      "        [32100,  8816,   891,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.5230,  4.1530,  2.0689,  ..., -4.1666, -3.6002, -2.1376],\n",
      "        [ 5.6120,  4.0016,  1.9938,  ..., -3.8686, -3.9075, -2.4526],\n",
      "        [ 5.7606,  4.1186,  2.0750,  ..., -3.9787, -3.9176, -2.6433],\n",
      "        ...,\n",
      "        [ 8.9291,  4.4880,  1.3362,  ..., -4.1124, -3.5604, -3.1805],\n",
      "        [ 8.9922,  4.1762,  1.2801,  ..., -4.0828, -3.4602, -3.1196],\n",
      "        [ 9.0028,  4.1943,  1.3124,  ..., -4.0024, -3.4570, -3.0048]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([    3, 17499,   615,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1311,     3,  ...,     0,     0,     0],\n",
      "        [32100,    86,    74,  ...,     0,     0,     0],\n",
      "        [32100,   374, 14737,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  2701,  ...,     0,     0,     0],\n",
      "        [32100,  1674,   675,  ...,     0,     0,     0],\n",
      "        [32100,     3,     2,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.8786,  4.5381,  2.1280,  ..., -4.2134, -3.7533, -2.4230],\n",
      "        [ 5.5960,  3.9214,  2.0604,  ..., -4.1267, -3.7921, -2.4233],\n",
      "        [ 5.8137,  4.2252,  2.1238,  ..., -4.2138, -3.9723, -2.5719],\n",
      "        ...,\n",
      "        [ 9.0087,  3.9182,  1.1700,  ..., -3.8621, -3.3309, -2.9262],\n",
      "        [ 9.0034,  3.8083,  1.1789,  ..., -3.8204, -3.1554, -3.0526],\n",
      "        [ 9.0303,  3.8014,  1.1506,  ..., -4.0358, -3.3905, -3.1120]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1311,    3, 1878,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 10007,  4186,  ...,     0,     0,     0],\n",
      "        [32100,  6560,  8964,  ...,     0,     0,     0],\n",
      "        [32100,     3,     2,  ..., 13147,  1047,     1],\n",
      "        ...,\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        [32100,   316,  3983,  ...,     0,     0,     0],\n",
      "        [32100,  1122,  1505,  ...,    35,    74,     1]], device='cuda:0')\n",
      "tensor([[ 5.0561,  3.9325,  2.2115,  ..., -3.9205, -3.6543, -2.2059],\n",
      "        [ 5.3593,  3.8545,  2.0142,  ..., -4.1443, -3.7264, -2.4311],\n",
      "        [ 5.3043,  3.9271,  2.2562,  ..., -3.9653, -3.8515, -2.4013],\n",
      "        ...,\n",
      "        [ 8.3443,  5.2115,  1.8341,  ..., -4.4946, -4.0742, -3.0897],\n",
      "        [ 8.1219,  5.1622,  2.0612,  ..., -4.5791, -4.1333, -3.0927],\n",
      "        [ 8.8087,  4.8302,  1.5193,  ..., -4.3079, -3.6285, -3.1258]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([10007,  4186,  4069,  ...,    74,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1920,  2064,  ...,     0,     0,     0],\n",
      "        [32100,   292,  3766,  ...,     0,     0,     0],\n",
      "        [32100,   644, 13636,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   389, 30227,  ...,    67,  4052,     1],\n",
      "        [32100,  1674,    90,  ...,     0,     0,     0],\n",
      "        [32100,   660,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9744,  3.7483,  2.1207,  ..., -4.0090, -3.6150, -2.1415],\n",
      "        [ 5.5400,  3.8782,  2.3265,  ..., -4.0986, -3.8707, -2.6924],\n",
      "        [ 5.4043,  3.9433,  2.2886,  ..., -4.1026, -3.7920, -2.4672],\n",
      "        ...,\n",
      "        [ 9.0256,  3.7071,  1.1166,  ..., -3.9598, -3.1864, -3.0584],\n",
      "        [ 9.0252,  3.9069,  1.0802,  ..., -4.0054, -3.3049, -3.1453],\n",
      "        [ 9.0193,  3.6665,  1.1107,  ..., -3.9132, -3.3193, -3.0552]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1920, 2064,    3,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   890, 30485,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0],\n",
      "        [32100,  2167, 24567,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  3941,   177,  ...,   436,     5,     1],\n",
      "        [32100,  2167,   493,  ...,     0,     0,     0],\n",
      "        [32100,  1674, 26683,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1487,  4.0000,  2.2618,  ..., -4.1024, -3.5452, -2.1256],\n",
      "        [ 5.6684,  4.2669,  2.2531,  ..., -4.1484, -3.9236, -2.5406],\n",
      "        [ 5.8361,  3.8718,  2.1423,  ..., -4.0782, -3.9363, -2.6440],\n",
      "        ...,\n",
      "        [ 9.0039,  4.2442,  1.1641,  ..., -4.0827, -3.4025, -3.0700],\n",
      "        [ 9.0312,  3.9379,  1.2574,  ..., -3.9156, -3.4919, -3.1028],\n",
      "        [ 8.9659,  4.4294,  1.4000,  ..., -4.0381, -3.5586, -3.1681]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  890, 30485, 19109,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   644,  1177,  ...,     0,     0,     0],\n",
      "        [32100,   292, 18226,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        [32100,  1185,   436,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0025,  3.7606,  2.1136,  ..., -4.0209, -3.6925, -2.2628],\n",
      "        [ 5.5187,  4.1338,  2.2856,  ..., -4.1374, -3.8885, -2.5983],\n",
      "        [ 5.5310,  4.1059,  2.0570,  ..., -3.9940, -3.9144, -2.4719],\n",
      "        ...,\n",
      "        [ 8.9856,  4.3253,  1.3931,  ..., -4.0958, -3.5014, -3.1088],\n",
      "        [ 9.0366,  3.9455,  1.1780,  ..., -3.9467, -3.3670, -3.1474],\n",
      "        [ 9.0122,  4.2172,  1.2903,  ..., -4.0456, -3.5267, -3.1608]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 644, 1177,   16,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  4746, 19097,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,  4455,     7,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1122,  1177,  ...,     0,     0,     0],\n",
      "        [32100,     3,  7577,  ...,     0,     0,     0],\n",
      "        [32100, 10277,   637,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2171,  3.9084,  2.1653,  ..., -3.9403, -3.7914, -2.2138],\n",
      "        [ 5.5493,  3.9779,  2.2503,  ..., -4.0573, -3.8562, -2.5015],\n",
      "        [ 5.2502,  3.8047,  2.2625,  ..., -4.0949, -3.7599, -2.3651],\n",
      "        ...,\n",
      "        [ 8.9858,  3.5848,  1.0496,  ..., -3.8422, -3.0827, -3.0806],\n",
      "        [ 9.0261,  3.8069,  1.2162,  ..., -3.8350, -3.2006, -3.0371],\n",
      "        [ 9.0160,  3.8288,  1.2104,  ..., -3.9380, -3.2743, -3.1687]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 4746, 19097,    52,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 19146, 16608,  ...,     0,     0,     0],\n",
      "        [32100,  1811, 10151,  ...,     0,     0,     0],\n",
      "        [32100,   781,  7392,  ..., 15067,   401,     1],\n",
      "        ...,\n",
      "        [32100, 19146,  5424,  ...,     0,     0,     0],\n",
      "        [32100,  2742,   558,  ...,     0,     0,     0],\n",
      "        [32100,  1311,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2645,  3.9305,  2.0518,  ..., -3.9713, -3.6566, -2.3456],\n",
      "        [ 6.4243,  4.4137,  2.0179,  ..., -4.3624, -3.9642, -2.6515],\n",
      "        [ 5.2824,  3.8951,  2.0583,  ..., -4.0934, -3.6065, -2.3203],\n",
      "        ...,\n",
      "        [ 9.0095,  3.6745,  1.0054,  ..., -3.8294, -3.2432, -3.1322],\n",
      "        [ 9.0158,  3.8203,  1.1876,  ..., -4.0155, -3.3034, -3.0905],\n",
      "        [ 9.0048,  3.5833,  1.1191,  ..., -3.7441, -3.2118, -2.9831]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([19146, 16608,    41,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1185,  3123,  ...,     0,     0,     0],\n",
      "        [32100, 13949,     3,  ...,     0,     0,     0],\n",
      "        [32100,   660,  6455,  ...,  8330,    15,     1],\n",
      "        ...,\n",
      "        [32100,     3,  7577,  ...,     0,     0,     0],\n",
      "        [32100,  6560,   637,  ...,     0,     0,     0],\n",
      "        [32100,   264, 11327,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.4234,  3.9748,  2.0309,  ..., -4.2325, -3.7350, -2.2317],\n",
      "        [ 5.0599,  3.7826,  2.0447,  ..., -4.1178, -3.7881, -2.2770],\n",
      "        [ 5.5408,  3.9953,  2.0775,  ..., -4.0564, -3.8567, -2.4951],\n",
      "        ...,\n",
      "        [ 9.0132,  4.1959,  1.2318,  ..., -4.0463, -3.3483, -3.1121],\n",
      "        [ 9.0376,  3.9796,  1.3175,  ..., -4.0796, -3.3618, -3.0365],\n",
      "        [ 9.0380,  3.9860,  1.2061,  ..., -4.0663, -3.3051, -3.0419]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1185, 3123, 1149,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  7073,    15,  ...,     0,     0,     0],\n",
      "        [32100,  9654, 12626,  ...,     0,     0,     0],\n",
      "        [32100,   848,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100, 22839,    15,  ...,     0,     0,     0],\n",
      "        [32100,   316,   890,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0836,  3.8923,  2.2603,  ..., -4.0003, -3.7483, -2.2971],\n",
      "        [ 5.3534,  3.8387,  2.3784,  ..., -3.8280, -3.9198, -2.5702],\n",
      "        [ 5.5444,  3.9982,  2.3345,  ..., -4.1453, -3.9341, -2.5323],\n",
      "        ...,\n",
      "        [ 9.0407,  4.2960,  1.3189,  ..., -4.1412, -3.4248, -3.1010],\n",
      "        [ 9.0314,  4.3721,  1.3610,  ..., -4.1234, -3.4885, -3.2041],\n",
      "        [ 9.0269,  4.3420,  1.2379,  ..., -4.0863, -3.4734, -3.2417]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([7073,   15, 1743,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:06,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  7672,     3,  ...,     3, 21342,     1],\n",
      "        [32100, 23764,     6,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  6905,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        [32100,  1920,    89,  ...,     6,     3,     1],\n",
      "        [32100,   374, 14737,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9834,  3.9547,  2.1506,  ..., -4.0475, -3.6274, -2.1031],\n",
      "        [ 5.1492,  3.7733,  2.1294,  ..., -4.0607, -3.7711, -2.4439],\n",
      "        [ 5.7842,  4.1844,  2.3496,  ..., -4.0114, -3.9073, -2.4584],\n",
      "        ...,\n",
      "        [ 8.9958,  4.3509,  1.1845,  ..., -4.1293, -3.4835, -3.1931],\n",
      "        [ 8.9932,  4.5593,  1.3793,  ..., -4.1770, -3.5556, -3.2085],\n",
      "        [ 9.0083,  4.2975,  1.4287,  ..., -4.1925, -3.4937, -3.1989]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 7672,     3, 20962,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:07,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  4098,  2889,  ...,     5,     1,     0],\n",
      "        [32100,   878,     3,  ...,     0,     0,     0],\n",
      "        [32100,  2840,    19,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        [32100,  1811, 10151,  ...,     6,   732,     1],\n",
      "        [32100,   316,  9532,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0865,  3.8909,  2.3128,  ..., -3.9600, -3.8267, -2.3837],\n",
      "        [ 4.9858,  3.6740,  2.3788,  ..., -3.8972, -3.8072, -2.5021],\n",
      "        [ 5.2895,  3.9644,  2.3359,  ..., -3.7553, -3.6161, -2.6602],\n",
      "        ...,\n",
      "        [ 9.0189,  3.8600,  1.1208,  ..., -3.8692, -3.1763, -3.0498],\n",
      "        [ 9.0624,  3.8483,  1.0651,  ..., -3.8929, -3.2506, -3.0622],\n",
      "        [ 9.0386,  3.7709,  1.1739,  ..., -3.9709, -3.2467, -3.2358]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([4098, 2889, 3775,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:08,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1318,  5728,  ...,     3, 11806,     1],\n",
      "        [32100, 11280,   324,  ...,     0,     0,     0],\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   644,  3967,  ...,     0,     0,     0],\n",
      "        [32100,  2858,    67,  ...,  4256,     3,     1],\n",
      "        [32100, 14649,   404,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1712,  3.7735,  2.3659,  ..., -3.9897, -3.7208, -2.3967],\n",
      "        [ 4.9878,  3.7632,  2.3739,  ..., -3.9751, -3.7664, -2.3773],\n",
      "        [ 5.2046,  3.9339,  2.2862,  ..., -3.8240, -3.7916, -2.4332],\n",
      "        ...,\n",
      "        [ 8.9848,  4.3876,  1.3239,  ..., -4.0246, -3.3673, -3.0574],\n",
      "        [ 9.0694,  4.1180,  1.3646,  ..., -4.1044, -3.3848, -3.0311],\n",
      "        [ 9.0307,  4.2462,  1.4684,  ..., -4.1260, -3.4582, -3.1208]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1318, 5728,  890,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:08,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   660,     3,  ...,     0,     0,     0],\n",
      "        [32100,  1122,    36,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,  8787,   362,     1],\n",
      "        ...,\n",
      "        [32100,  1122,   229,  ...,     0,     0,     0],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2187,  4.1022,  2.0056,  ..., -4.1843, -3.5155, -2.0493],\n",
      "        [ 5.4271,  4.0920,  1.9802,  ..., -4.4590, -3.6551, -2.4708],\n",
      "        [ 6.3785,  4.6550,  2.1591,  ..., -4.4623, -3.8253, -2.7919],\n",
      "        ...,\n",
      "        [ 8.9716,  4.7150,  1.3622,  ..., -4.2094, -3.6229, -3.1973],\n",
      "        [ 9.0581,  4.3347,  1.3764,  ..., -4.2297, -3.4449, -3.1499],\n",
      "        [ 8.9832,  4.5622,  1.3090,  ..., -4.2406, -3.5705, -3.0099]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  660,     3, 20962,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:09,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316, 23450,  ...,     3,    15,     1],\n",
      "        [32100,  8816,   891,  ...,     0,     0,     0],\n",
      "        [32100,  1185,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   644,   551,  ...,     0,     0,     0],\n",
      "        [32100,   316, 31863,  ...,     0,     0,     0],\n",
      "        [32100,     3, 26114,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1034,  3.7875,  1.9566,  ..., -3.7544, -3.7273, -2.4253],\n",
      "        [ 5.5974,  4.0484,  2.2859,  ..., -4.1979, -4.0256, -2.6000],\n",
      "        [ 5.0013,  3.8201,  2.2815,  ..., -3.8837, -3.9250, -2.3396],\n",
      "        ...,\n",
      "        [ 9.0598,  3.8367,  1.1901,  ..., -4.0240, -3.2590, -2.9979],\n",
      "        [ 9.0331,  3.9839,  1.1239,  ..., -3.9441, -3.3303, -3.1036],\n",
      "        [ 9.0345,  3.7508,  1.3317,  ..., -3.8970, -3.2544, -2.9936]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  316, 23450, 11427,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:09,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,    86,    74,  ...,     0,     0,     0],\n",
      "        [32100,  6483,   760,  ..., 21984,    23,     1],\n",
      "        [32100,   660, 19146,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  4746,  1392,  ...,     3,    49,     1],\n",
      "        [32100,  4746,  1699,  ...,     0,     0,     0],\n",
      "        [32100,  7672,    71,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9953,  3.9744,  2.1306,  ..., -3.7857, -3.7674, -2.4091],\n",
      "        [ 5.2925,  3.8051,  2.1649,  ..., -3.9927, -3.9059, -2.4770],\n",
      "        [ 5.4619,  3.7292,  2.2098,  ..., -3.8339, -3.8953, -2.6579],\n",
      "        ...,\n",
      "        [ 9.0133,  3.7500,  0.9898,  ..., -3.7988, -3.0028, -2.9886],\n",
      "        [ 9.0262,  3.6942,  1.1619,  ..., -3.8108, -3.0899, -3.0057],\n",
      "        [ 9.0113,  3.7365,  1.2694,  ..., -3.8692, -3.3013, -3.1004]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([86, 74,  3,  ...,  0,  0,  0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:10,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,  5837,  ...,     0,     0,     0],\n",
      "        [32100,  1122, 23275,  ...,     9,    26,     1],\n",
      "        [32100,  2739,     3,  ...,    49,  4612,     1],\n",
      "        ...,\n",
      "        [32100,   325,  4932,  ..., 13879,   425,     1],\n",
      "        [32100,  2742,     3,  ...,     0,     0,     0],\n",
      "        [32100,  4443, 10726,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0590,  3.7973,  2.0620,  ..., -3.9311, -3.7066, -2.3376],\n",
      "        [ 5.6984,  4.1499,  2.3026,  ..., -4.1950, -3.9608, -2.4867],\n",
      "        [ 5.5934,  3.8982,  2.2327,  ..., -4.1101, -3.9838, -2.5327],\n",
      "        ...,\n",
      "        [ 9.0387,  3.6567,  1.0305,  ..., -3.7974, -3.0510, -3.1149],\n",
      "        [ 9.0189,  3.7833,  1.2262,  ..., -3.9427, -3.2281, -3.0523],\n",
      "        [ 9.0577,  3.7184,  1.2278,  ..., -3.8684, -3.2372, -2.9993]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 316, 5837, 5451,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:11,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  2742,    74,  ...,     0,     0,     0],\n",
      "        [32100,  1674, 27023,  ...,     0,     0,     0],\n",
      "        [32100, 18843, 23420,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100, 10037,     3,  ...,     0,     0,     0],\n",
      "        [32100,  2167,    29,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0094,  3.9800,  2.1712,  ..., -3.9193, -3.7600, -2.3905],\n",
      "        [ 5.7106,  4.0356,  2.2975,  ..., -4.2131, -3.8981, -2.4720],\n",
      "        [ 5.4838,  3.9093,  2.3000,  ..., -4.1930, -3.9962, -2.5564],\n",
      "        ...,\n",
      "        [ 9.0255,  4.4908,  1.2350,  ..., -4.1844, -3.5337, -3.0736],\n",
      "        [ 9.0597,  4.3008,  1.2997,  ..., -4.1431, -3.3894, -3.1485],\n",
      "        [ 9.0378,  4.3034,  1.1759,  ..., -4.1617, -3.5451, -3.0688]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 2742,    74, 20242,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:11,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,     3,  ...,     6,     3,     1],\n",
      "        [32100, 18843,     7,  ...,   172, 18241,     1],\n",
      "        [32100,  1185, 13203,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,    86,     3,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        [32100,   264, 11327,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.4601,  4.0860,  2.3091,  ..., -3.9586, -3.9389, -2.6638],\n",
      "        [ 5.7241,  4.0423,  2.3427,  ..., -4.1448, -4.0303, -2.5529],\n",
      "        [ 5.2483,  3.8004,  2.0456,  ..., -3.9197, -3.8282, -2.5895],\n",
      "        ...,\n",
      "        [ 9.0797,  3.7572,  1.2271,  ..., -3.8637, -3.3628, -3.0794],\n",
      "        [ 9.0732,  4.0766,  1.2274,  ..., -3.9793, -3.3150, -3.1534],\n",
      "        [ 9.0520,  4.0345,  1.1913,  ..., -3.9172, -3.3171, -3.1347]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([316,   3, 122,  ...,   0,   0,   0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:12,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  8816, 13758,  ...,     0,     0,     0],\n",
      "        [32100,   644,     3,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  2701,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1122,  3402,  ...,     0,     0,     0],\n",
      "        [32100, 11565,  3766,  ...,     0,     0,     0],\n",
      "        [32100,   316,  6973,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8848,  3.7352,  2.1283,  ..., -3.9600, -3.7040, -2.2150],\n",
      "        [ 5.6454,  3.9294,  2.3129,  ..., -4.2282, -4.0294, -2.6275],\n",
      "        [ 5.2887,  3.9514,  2.1588,  ..., -3.8583, -3.8171, -2.6260],\n",
      "        ...,\n",
      "        [ 9.0549,  4.1881,  1.2568,  ..., -4.0522, -3.4348, -3.1094],\n",
      "        [ 9.0441,  4.0381,  1.3126,  ..., -3.9028, -3.3101, -2.9545],\n",
      "        [ 9.0783,  3.9740,  1.2083,  ..., -4.0550, -3.4197, -3.1711]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 8816, 13758,   588,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:12,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1674,   177,  ...,     0,     0,     0],\n",
      "        [32100,  1811,  1778,  ..., 27638,    35,     1],\n",
      "        [32100,  9654,  6368,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316, 15402,  ...,     0,     0,     0],\n",
      "        [32100,   848, 14802,  ...,    89,  7118,     1],\n",
      "        [32100,   644, 13636,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.3057,  4.1404,  2.1777,  ..., -4.2204, -3.9255, -2.4264],\n",
      "        [ 5.7719,  4.0552,  2.1749,  ..., -4.2524, -3.9264, -2.5650],\n",
      "        [ 5.6240,  3.8557,  2.1485,  ..., -4.2043, -4.0623, -2.7045],\n",
      "        ...,\n",
      "        [ 8.7832,  5.1344,  1.5438,  ..., -4.3233, -3.8604, -3.3283],\n",
      "        [ 8.9606,  4.7492,  1.4776,  ..., -4.2697, -3.7336, -3.1755],\n",
      "        [ 8.6087,  5.2682,  1.8377,  ..., -4.4780, -3.9487, -3.1915]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1674,  177, 1050,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:13,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1185,   745,  ...,     0,     0,     0],\n",
      "        [32100, 31660,    93,  ...,     0,     0,     0],\n",
      "        [32100,  4098,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  6907,  6530,  ...,     0,     0,     0],\n",
      "        [32100,  1122,   229,  ...,     0,     0,     0],\n",
      "        [32100,  9654,   229,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2966,  3.9548,  2.1051,  ..., -4.2858, -3.8906, -2.5266],\n",
      "        [ 5.5310,  3.8340,  2.2749,  ..., -4.0839, -4.1090, -2.5231],\n",
      "        [ 5.6372,  3.9091,  2.3594,  ..., -4.1288, -4.0926, -2.7451],\n",
      "        ...,\n",
      "        [ 9.0307,  4.0003,  1.1903,  ..., -3.9103, -3.2520, -3.0547],\n",
      "        [ 9.0713,  3.8574,  1.0611,  ..., -3.8802, -3.2157, -3.1040],\n",
      "        [ 9.1011,  3.8344,  1.0231,  ..., -3.9232, -3.2808, -3.1138]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1185,  745, 1149,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:14,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,     3, 15900,  ...,    74,     3,     1],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     3,  4060,     1],\n",
      "        ...,\n",
      "        [32100,    86, 20878,  ...,     0,     0,     0],\n",
      "        [32100,  1821,  6175,  ...,     0,     0,     0],\n",
      "        [32100,    41,  8639,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1118,  3.8997,  2.2813,  ..., -3.8799, -3.7261, -2.4164],\n",
      "        [ 5.5269,  4.0145,  2.1655,  ..., -4.1509, -4.0675, -2.5800],\n",
      "        [ 5.4573,  3.8937,  2.2875,  ..., -4.0588, -3.9517, -2.6192],\n",
      "        ...,\n",
      "        [ 9.0746,  4.1315,  1.2365,  ..., -4.0613, -3.4716, -3.1215],\n",
      "        [ 9.0748,  4.0452,  1.0912,  ..., -4.0197, -3.3865, -3.0804],\n",
      "        [ 9.0611,  4.2216,  1.1531,  ..., -4.0473, -3.4018, -3.1858]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([    3, 15900,    67,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:14,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1318, 25349,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  6905,  ...,     0,     0,     0],\n",
      "        [32100,  2820, 30683,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100, 18843, 27932,  ...,  2800,     3,     1],\n",
      "        [32100,   316, 11726,  ...,   404,  3766,     1],\n",
      "        [32100, 16232, 12561,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9800,  3.9591,  2.1643,  ..., -4.0838, -3.6139, -2.1071],\n",
      "        [ 6.0276,  4.3259,  2.1310,  ..., -4.3939, -3.9751, -2.6849],\n",
      "        [ 5.7720,  4.1532,  2.2878,  ..., -4.1351, -3.9947, -2.7395],\n",
      "        ...,\n",
      "        [ 8.2012,  5.4028,  1.9130,  ..., -4.6961, -4.1150, -3.2015],\n",
      "        [ 8.2590,  5.4559,  1.9469,  ..., -4.6414, -4.0526, -3.0729],\n",
      "        [ 8.5895,  5.2914,  1.6480,  ..., -4.3845, -3.9383, -3.1136]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 1318, 25349,    35,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:15,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 12625,  1811,  ...,     0,     0,     0],\n",
      "        [32100, 16419,  9344,  ...,     0,     0,     0],\n",
      "        [32100,  9654,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1122,  3775,  ...,     0,     0,     0],\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        [32100,  4746, 10974,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.8555,  4.5156,  2.1570,  ..., -4.4138, -3.6638, -2.2431],\n",
      "        [ 5.8680,  4.4243,  2.2254,  ..., -4.3331, -3.9895, -2.6311],\n",
      "        [ 5.6963,  4.0838,  2.1038,  ..., -4.1284, -4.0109, -2.6387],\n",
      "        ...,\n",
      "        [ 9.0896,  3.9063,  1.2050,  ..., -3.9396, -3.2335, -3.0639],\n",
      "        [ 9.0600,  3.9955,  1.1732,  ..., -3.9044, -3.2136, -3.0554],\n",
      "        [ 9.0844,  3.8251,  1.1418,  ..., -3.9085, -3.2896, -3.0338]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([12625,  1811,   624,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:15,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  9654,   551,  ...,     0,     0,     0],\n",
      "        [32100,     3,    18,  ...,     0,     0,     0],\n",
      "        [32100, 12225,    49,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,     3,  8914,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        [32100,  2751,    67,  ...,     7,   403,     1]], device='cuda:0')\n",
      "tensor([[ 4.9482,  3.8837,  2.1127,  ..., -4.0067, -3.6588, -2.3012],\n",
      "        [ 5.5740,  4.1216,  2.2382,  ..., -4.1322, -4.0326, -2.6908],\n",
      "        [ 5.4480,  3.7799,  1.9991,  ..., -3.9668, -3.9606, -2.6560],\n",
      "        ...,\n",
      "        [ 6.5182,  4.5803,  2.3232,  ..., -4.3814, -4.1184, -2.8644],\n",
      "        [ 7.6915,  5.2684,  2.0673,  ..., -4.4232, -4.3173, -3.1317],\n",
      "        [ 8.1291,  5.5134,  1.8364,  ..., -4.4267, -4.0196, -3.0204]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([9654,  551,   74,  ...,  403,    1,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:16,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1122,  5282,  ...,     0,     0,     0],\n",
      "        [32100,   264,  7816,  ...,     0,     0,     0],\n",
      "        [32100,  2167, 31865,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   309,     5,  ...,     0,     0,     0],\n",
      "        [32100,  1674, 27023,  ...,     3,  5162,     1],\n",
      "        [32100,   389, 30227,  ...,    67,   558,     1]], device='cuda:0')\n",
      "tensor([[ 5.0681,  4.0343,  2.1256,  ..., -3.8937, -3.6999, -2.1534],\n",
      "        [ 5.2179,  3.9024,  2.2497,  ..., -4.1531, -3.8068, -2.5731],\n",
      "        [ 5.7455,  4.0034,  2.0332,  ..., -4.1962, -3.9473, -2.6725],\n",
      "        ...,\n",
      "        [ 5.7066,  4.0691,  2.2790,  ..., -4.2033, -4.1077, -2.6111],\n",
      "        [ 5.1731,  3.7107,  2.3338,  ..., -3.9326, -3.9078, -2.5226],\n",
      "        [ 8.0572,  5.2679,  2.1114,  ..., -4.4852, -4.2812, -3.1105]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1122, 5282, 3423,  ...,  558,    1,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:17,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  2751,   218,  ...,     0,     0,     0],\n",
      "        [32100, 14649, 12443,  ...,     0,     0,     0],\n",
      "        [32100,   264, 11327,  ...,   193,  9821,     1],\n",
      "        ...,\n",
      "        [32100,  1318,  3861,  ...,     0,     0,     0],\n",
      "        [32100,   325,  4932,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.9657,  4.4209,  2.0882,  ..., -4.1897, -3.5153, -2.2412],\n",
      "        [ 5.9530,  4.5786,  2.2917,  ..., -4.4199, -4.0062, -2.6229],\n",
      "        [ 6.7391,  4.8492,  1.9883,  ..., -4.6185, -4.0236, -2.7348],\n",
      "        ...,\n",
      "        [ 7.3726,  5.1946,  2.1040,  ..., -4.5668, -4.1344, -2.9770],\n",
      "        [ 8.7459,  5.2364,  1.7090,  ..., -4.4984, -3.9415, -3.1010],\n",
      "        [ 8.4605,  5.2691,  1.8494,  ..., -4.5029, -4.0464, -3.1095]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([2751,  218,  266,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [00:17,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1140,     3,  ...,     0,     0,     0],\n",
      "        [32100,   292,   404,  ...,  9188,  8654,     1],\n",
      "        [32100,  1821, 12579,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        [32100,  1122, 29510,  ...,     0,     0,     0],\n",
      "        [32100,  7672,   891,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8116,  3.6482,  2.1031,  ..., -3.7612, -3.7458, -2.3713],\n",
      "        [ 4.8890,  3.7651,  2.2489,  ..., -3.8423, -3.8957, -2.4201],\n",
      "        [ 5.4819,  3.6326,  2.1755,  ..., -3.8930, -4.0144, -2.6752],\n",
      "        ...,\n",
      "        [ 9.0578,  4.5787,  1.3332,  ..., -4.1933, -3.6143, -3.1418],\n",
      "        [ 9.0695,  4.3929,  1.1932,  ..., -4.1422, -3.4235, -3.2237],\n",
      "        [ 9.0879,  4.2562,  1.2147,  ..., -4.0479, -3.4623, -3.0453]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1140,    3,   51,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:18,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,  5837,  ...,     0,     0,     0],\n",
      "        [32100,    86,  1743,  ...,     0,     0,     0],\n",
      "        [32100,   660,  7077,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,     3, 26114,  ...,     0,     0,     0],\n",
      "        [32100,  3128, 12555,  ...,     0,     0,     0],\n",
      "        [32100,   374, 14737,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2002,  4.1684,  2.2750,  ..., -3.7216, -3.9362, -2.4444],\n",
      "        [ 5.5047,  4.0813,  2.1977,  ..., -4.1567, -3.9547, -2.5397],\n",
      "        [ 5.4507,  3.8836,  1.9584,  ..., -3.9608, -3.8872, -2.4703],\n",
      "        ...,\n",
      "        [ 9.0402,  4.6484,  1.3707,  ..., -4.1825, -3.6682, -3.1620],\n",
      "        [ 9.0706,  4.5701,  1.3377,  ..., -4.2398, -3.5378, -3.2341],\n",
      "        [ 8.9984,  4.5833,  1.4102,  ..., -4.2045, -3.6498, -3.2456]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 316, 5837, 5451,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:18,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 20733,  3861,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  8816,     3,  ...,     6,   183,     1],\n",
      "        [32100, 23359,  1778,  ...,     0,     0,     0],\n",
      "        [32100,  2432,   236,  ...,   860,  7921,     1]], device='cuda:0')\n",
      "tensor([[ 4.9169,  3.8245,  2.2248,  ..., -3.9223, -3.6832, -2.3400],\n",
      "        [ 5.6614,  4.0268,  2.1434,  ..., -4.1789, -4.0075, -2.6058],\n",
      "        [ 5.5293,  4.0817,  2.0562,  ..., -4.1848, -3.9549, -2.5683],\n",
      "        ...,\n",
      "        [ 5.8798,  4.0715,  2.2248,  ..., -4.2365, -3.9606, -2.6993],\n",
      "        [ 6.3887,  4.5318,  2.2104,  ..., -4.1824, -4.2103, -2.8779],\n",
      "        [ 6.8542,  4.9802,  2.2170,  ..., -4.3161, -4.3274, -3.1059]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([20733,  3861,   559,  ...,  7921,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:19,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 16008,   558,  ...,     0,     0,     0],\n",
      "        [32100, 11280,   324,  ...,     0,     0,     0],\n",
      "        [32100,   316,  2802,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  2203,     3,  ...,     0,     0,     0],\n",
      "        [32100,   374, 14737,  ..., 13172,     6,     1],\n",
      "        [32100,  1185,  6905,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1604,  4.0253,  1.9963,  ..., -4.0871, -3.3230, -2.1846],\n",
      "        [ 5.7897,  4.3559,  2.2571,  ..., -4.2525, -4.0226, -2.5391],\n",
      "        [ 6.1402,  4.3915,  2.3072,  ..., -4.3436, -4.1859, -2.7271],\n",
      "        ...,\n",
      "        [ 9.1274,  4.0866,  1.2397,  ..., -4.1210, -3.3985, -3.1597],\n",
      "        [ 9.1249,  4.0378,  1.2673,  ..., -3.9765, -3.4048, -3.1235],\n",
      "        [ 9.0940,  4.0669,  1.1845,  ..., -3.9598, -3.2721, -2.9368]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([16008,   558,  5409,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:20,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 19304,    67,  ...,   680,   236,     1],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        [32100,   644,  1177,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  5070,    15,  ...,     0,     0,     0],\n",
      "        [32100,   644,  6822,  ...,     0,     0,     0],\n",
      "        [32100,   316,  3901,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.7028,  3.6551,  2.1499,  ..., -3.7552, -3.6423, -2.3342],\n",
      "        [ 4.8023,  3.6964,  2.2527,  ..., -3.9145, -3.8641, -2.3623],\n",
      "        [ 4.9830,  3.7486,  2.0406,  ..., -3.7849, -3.8340, -2.3836],\n",
      "        ...,\n",
      "        [ 9.0613,  4.5822,  1.4213,  ..., -4.3157, -3.6524, -3.1003],\n",
      "        [ 9.0209,  4.7285,  1.3611,  ..., -4.2919, -3.7020, -3.2639],\n",
      "        [ 9.0900,  4.3876,  1.4144,  ..., -4.1532, -3.5330, -3.0862]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([19304,    67,  5837,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [00:20,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1185,   745,  ...,     0,     0,     0],\n",
      "        [32100,  1185, 21179,  ...,     0,     0,     0],\n",
      "        [32100,  3128,   736,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1318, 13942,  ...,    47,     3,     1],\n",
      "        [32100,   292,   436,  ...,     0,     0,     0],\n",
      "        [32100, 23764, 14932,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0507,  3.8492,  2.0621,  ..., -4.0989, -3.5237, -2.1627],\n",
      "        [ 5.1437,  3.9428,  2.1854,  ..., -4.1036, -3.8558, -2.4530],\n",
      "        [ 5.4911,  4.1873,  2.0516,  ..., -4.2604, -3.9603, -2.5964],\n",
      "        ...,\n",
      "        [ 9.0764,  4.0015,  1.1808,  ..., -3.8548, -3.2444, -2.9802],\n",
      "        [ 9.1231,  3.7397,  1.0620,  ..., -3.9125, -3.1448, -2.9186],\n",
      "        [ 9.0838,  3.9681,  1.0837,  ..., -3.8995, -3.3296, -2.9649]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1185,  745,   67,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:21,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,    71,  7498,  ...,     0,     0,     0],\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  2010,  ...,    15,     7,     1],\n",
      "        ...,\n",
      "        [32100, 10277,    67,  ...,     0,     0,     0],\n",
      "        [32100,  1122,  6845,  ...,     0,     0,     0],\n",
      "        [32100,   925,  1703,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.6787,  3.7718,  2.1137,  ..., -3.8864, -3.6572, -2.2049],\n",
      "        [ 5.2818,  3.8150,  2.1186,  ..., -4.0955, -3.9584, -2.4111],\n",
      "        [ 5.2716,  3.9202,  2.2925,  ..., -4.0216, -3.9154, -2.5133],\n",
      "        ...,\n",
      "        [ 9.1201,  4.2445,  1.2324,  ..., -4.0892, -3.5169, -3.0888],\n",
      "        [ 9.1480,  4.1814,  1.2356,  ..., -4.0441, -3.3977, -3.1473],\n",
      "        [ 9.1283,  4.2119,  1.2488,  ..., -4.1562, -3.4469, -3.1687]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  71, 7498,  551,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:22,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 23359,  4755,  ...,     0,     0,     0],\n",
      "        [32100,  1821,    74,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  3766,  ..., 22655,   266,     1],\n",
      "        ...,\n",
      "        [32100,  9654,   675,  ...,     0,     0,     0],\n",
      "        [32100,  2751,  1149,  ...,     0,     0,     0],\n",
      "        [32100,  1185,   730,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0637,  3.8026,  2.1391,  ..., -3.9054, -3.7045, -2.4297],\n",
      "        [ 5.3807,  3.9577,  2.3359,  ..., -4.1000, -3.9130, -2.3788],\n",
      "        [ 5.6175,  3.9743,  2.1590,  ..., -4.3685, -4.1109, -2.6747],\n",
      "        ...,\n",
      "        [ 9.1056,  3.8913,  1.0014,  ..., -3.9241, -3.2642, -3.0320],\n",
      "        [ 9.1055,  3.7785,  1.0571,  ..., -3.8113, -3.1875, -3.0168],\n",
      "        [ 9.0752,  3.8434,  0.9909,  ..., -3.8374, -3.2425, -3.0143]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([23359,  4755,   219,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:22,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   272, 29325,  ...,  4100,  1033,     1],\n",
      "        [32100,  1674,   253,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,   362,  6367,     1],\n",
      "        ...,\n",
      "        [32100,    86,    74,  ...,     0,     0,     0],\n",
      "        [32100,  1140,  3998,  ...,     0,     0,     0],\n",
      "        [32100,   389, 30227,  ...,     3, 19357,     1]], device='cuda:0')\n",
      "tensor([[ 4.9323,  3.9033,  2.1888,  ..., -3.8709, -3.7762, -2.2732],\n",
      "        [ 5.2122,  3.8087,  2.1333,  ..., -3.9026, -3.9437, -2.5060],\n",
      "        [ 5.3714,  3.8827,  2.4705,  ..., -3.9849, -3.9960, -2.6001],\n",
      "        ...,\n",
      "        [ 5.4204,  3.9305,  2.4092,  ..., -4.0046, -4.0370, -2.6860],\n",
      "        [ 5.8532,  4.0694,  2.1933,  ..., -4.2056, -4.1365, -2.7826],\n",
      "        [ 8.0557,  5.3965,  1.9755,  ..., -4.4480, -4.1417, -2.9252]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  272, 29325, 24816,  ..., 19357,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:23,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100, 12625,  5648,  ...,     0,     0,     0],\n",
      "        [32100,  1122,  1177,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  2513,    67,  ...,     0,     0,     0],\n",
      "        [32100,  1392,  2800,  ...,     0,     0,     0],\n",
      "        [32100,   264,  1177,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0057,  4.0981,  2.3312,  ..., -3.9183, -3.8041, -2.2022],\n",
      "        [ 5.6224,  4.2384,  2.3295,  ..., -4.1749, -4.0413, -2.6223],\n",
      "        [ 5.7441,  4.0621,  2.1066,  ..., -4.1218, -4.1321, -2.6961],\n",
      "        ...,\n",
      "        [ 9.1350,  3.8117,  1.1357,  ..., -3.9584, -3.1639, -3.0032],\n",
      "        [ 9.1305,  3.8624,  1.1011,  ..., -3.9230, -3.3958, -3.0719],\n",
      "        [ 9.0871,  3.7742,  1.1091,  ..., -3.8113, -3.2134, -3.0171]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 1674,     3, 11950,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:23,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  3941,  1999,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  3766,  ...,     0,     0,     0],\n",
      "        [32100,  5837,  5451,  ...,   195,   510,     1],\n",
      "        ...,\n",
      "        [32100,   660, 14349,  ...,     0,     0,     0],\n",
      "        [32100,  1985,    74,  ...,     0,     0,     0],\n",
      "        [32100,   493, 15297,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.4041,  4.3768,  2.0120,  ..., -4.1263, -3.4359, -2.1047],\n",
      "        [ 5.4235,  4.0843,  2.1329,  ..., -4.1645, -3.9375, -2.5702],\n",
      "        [ 6.1921,  4.4260,  2.0080,  ..., -4.2521, -4.0955, -2.8385],\n",
      "        ...,\n",
      "        [ 9.1038,  4.0026,  1.0548,  ..., -3.9385, -3.2855, -3.1459],\n",
      "        [ 9.1089,  4.1707,  1.2306,  ..., -3.9247, -3.3411, -3.1466],\n",
      "        [ 9.1146,  3.8502,  1.0424,  ..., -3.9635, -3.4140, -3.1311]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 3941,  1999, 23131,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:24,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  8816,     3,  ...,  3969,  7010,     1],\n",
      "        [32100,  4098,   559,  ...,     0,     0,     0],\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  2742,     3,  ...,     7,    35,     1],\n",
      "        [32100,  1185,    26,  ...,     0,     0,     0],\n",
      "        [32100, 12225,    49,  ...,     3, 21728,     1]], device='cuda:0')\n",
      "tensor([[ 5.0704,  3.8854,  2.3773,  ..., -4.1453, -3.8707, -2.2977],\n",
      "        [ 5.0629,  3.7222,  2.2571,  ..., -3.9902, -3.9925, -2.5459],\n",
      "        [ 5.3065,  4.0818,  2.2276,  ..., -3.9845, -3.8926, -2.4015],\n",
      "        ...,\n",
      "        [ 8.3232,  5.4756,  1.9647,  ..., -4.6912, -4.1513, -3.0989],\n",
      "        [ 8.8702,  5.0609,  1.6842,  ..., -4.5632, -3.9363, -3.1855],\n",
      "        [ 8.2609,  5.4948,  1.9392,  ..., -4.5774, -4.1908, -3.1533]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 8816,     3, 20962,  ..., 21728,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:25,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316, 13879,  ...,     3, 19189,     1],\n",
      "        [32100,  1674,    21,  ...,     0,     0,     0],\n",
      "        [32100,  1662,  2352,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,  7083,    16,     1],\n",
      "        [32100,   389, 30227,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8928,  3.7987,  2.4443,  ..., -4.0008, -3.8726, -2.4125],\n",
      "        [ 5.0180,  3.7679,  2.2728,  ..., -3.7897, -3.9284, -2.4126],\n",
      "        [ 5.4367,  3.9814,  2.3096,  ..., -3.9526, -3.9852, -2.6052],\n",
      "        ...,\n",
      "        [ 9.1129,  4.4010,  1.2737,  ..., -4.1980, -3.5375, -3.2184],\n",
      "        [ 9.1315,  4.4646,  1.3972,  ..., -4.1381, -3.5494, -3.2341],\n",
      "        [ 9.1167,  4.3122,  1.2252,  ..., -4.0262, -3.4919, -3.1232]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  316, 13879,   425,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42it [00:25,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1662,  6515,  ...,     0,     0,     0],\n",
      "        [32100,     3, 20962,  ...,     0,     0,     0],\n",
      "        [32100,  2203,   211,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  2701,  ...,     0,     0,     0],\n",
      "        [32100, 18843,  6906,  ...,     0,     0,     0],\n",
      "        [32100,  2742,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.4053,  4.2037,  2.2034,  ..., -4.0815, -3.7621, -2.2950],\n",
      "        [ 5.6863,  4.1561,  2.1954,  ..., -4.0946, -4.0617, -2.6784],\n",
      "        [ 5.6835,  4.2342,  2.2625,  ..., -3.9269, -4.0569, -2.7092],\n",
      "        ...,\n",
      "        [ 8.9715,  5.0016,  1.5064,  ..., -4.4048, -3.6955, -3.2050],\n",
      "        [ 8.8646,  5.1075,  1.7080,  ..., -4.3489, -3.8308, -3.1766],\n",
      "        [ 9.0486,  4.7908,  1.3947,  ..., -4.2747, -3.7363, -3.2986]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1662, 6515, 2589,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:26,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 23258, 16750,  ...,     0,     0,     0],\n",
      "        [32100, 18463,    36,  ...,     0,     0,     0],\n",
      "        [32100,  1185, 19603,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316,  7732,  ...,     0,     0,     0],\n",
      "        [32100,  1138,   122,  ...,     0,     0,     0],\n",
      "        [32100,  1185, 13341,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8739,  3.7848,  2.1667,  ..., -4.0462, -3.6074, -2.2262],\n",
      "        [ 7.3371,  5.3216,  2.0138,  ..., -4.7002, -4.1125, -2.9568],\n",
      "        [ 5.5084,  4.0101,  2.2401,  ..., -4.1935, -3.8000, -2.4750],\n",
      "        ...,\n",
      "        [ 9.1281,  3.8095,  1.0749,  ..., -3.8422, -3.2885, -3.1495],\n",
      "        [ 9.1376,  3.9139,  1.2036,  ..., -3.8671, -3.3137, -3.1719],\n",
      "        [ 9.1283,  3.6471,  1.1127,  ..., -3.8825, -3.3617, -3.1108]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([23258, 16750,     5,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:26,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  2858,  1324,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  3766,  ...,   311,  1403,     1],\n",
      "        [32100,  2167, 10808,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  8816,   183,  ...,     0,     0,     0],\n",
      "        [32100,   316,  2147,  ...,   426, 15263,     1],\n",
      "        [32100,  2751,    67,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8958,  3.7903,  2.1068,  ..., -3.9679, -3.6630, -2.3408],\n",
      "        [ 5.5016,  3.9587,  2.0982,  ..., -4.2185, -3.9820, -2.6932],\n",
      "        [ 5.0595,  3.9006,  2.0571,  ..., -4.0376, -3.9180, -2.4300],\n",
      "        ...,\n",
      "        [ 9.1436,  4.4961,  1.2916,  ..., -4.1469, -3.4638, -3.2741],\n",
      "        [ 9.0929,  4.5242,  1.4357,  ..., -4.0867, -3.5494, -3.1454],\n",
      "        [ 9.1366,  4.4849,  1.3827,  ..., -4.1292, -3.5856, -3.1905]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 2858,  1324, 15464,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:27,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,  5837,  ...,     0,     0,     0],\n",
      "        [32100,  1122,  1505,  ...,     0,     0,     0],\n",
      "        [32100, 11287,  3019,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  8816,   264,  ...,     0,     0,     0],\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  1854,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.0038,  3.9304,  2.1616,  ..., -3.9648, -3.6343, -2.1716],\n",
      "        [ 5.1638,  4.0688,  2.2180,  ..., -3.9138, -3.9760, -2.5603],\n",
      "        [ 5.5088,  3.9403,  2.1154,  ..., -4.1792, -3.9136, -2.5155],\n",
      "        ...,\n",
      "        [ 9.1588,  4.1143,  1.1818,  ..., -4.0187, -3.3212, -3.2053],\n",
      "        [ 9.1325,  4.2391,  1.0819,  ..., -4.1576, -3.3690, -3.2323],\n",
      "        [ 9.1130,  4.2587,  1.2174,  ..., -3.9654, -3.4710, -3.1155]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 316, 5837, 5451,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46it [00:28,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 10697, 24699,  ...,     0,     0,     0],\n",
      "        [32100,  1392,  8615,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1811,   177,  ...,     0,     0,     0],\n",
      "        [32100,  1920,   152,  ...,     0,     0,     0],\n",
      "        [32100,  9654, 22976,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.6671,  3.7897,  2.0862,  ..., -3.8293, -3.5332, -2.0851],\n",
      "        [ 5.2438,  3.8265,  2.2477,  ..., -4.0875, -3.8553, -2.4539],\n",
      "        [ 5.4405,  3.9923,  2.1063,  ..., -4.1762, -3.9940, -2.6156],\n",
      "        ...,\n",
      "        [ 9.1358,  4.5062,  1.4124,  ..., -4.1406, -3.5915, -3.2865],\n",
      "        [ 9.1089,  4.5001,  1.3102,  ..., -4.1044, -3.4994, -3.1947],\n",
      "        [ 9.1076,  4.5127,  1.2824,  ..., -4.1004, -3.5152, -3.0892]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([10697, 24699, 14633,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:28,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   660,  6455,  ...,     0,     0,     0],\n",
      "        [32100,  1122,     3,  ...,     0,     0,     0],\n",
      "        [32100,  7217,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,     3, 26114,  ...,     0,     0,     0],\n",
      "        [32100,   891, 13344,  ...,   218,   177,     1],\n",
      "        [32100,  9654,   229,  ...,     5,     1,     0]], device='cuda:0')\n",
      "tensor([[ 4.7405,  3.8302,  2.2229,  ..., -3.9111, -3.5782, -2.1630],\n",
      "        [ 5.6310,  4.0647,  2.3411,  ..., -4.1695, -4.1378, -2.6784],\n",
      "        [ 5.6265,  4.2117,  2.3288,  ..., -4.0838, -3.9187, -2.5821],\n",
      "        ...,\n",
      "        [ 9.0773,  4.7780,  1.3929,  ..., -4.2172, -3.5296, -3.0870],\n",
      "        [ 9.1509,  4.3553,  1.1888,  ..., -4.2291, -3.5962, -3.1912],\n",
      "        [ 9.1328,  4.4913,  1.1545,  ..., -4.2280, -3.4666, -3.2154]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 660, 6455,   36,  ...,    1,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:29,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   878,  7465,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  1199,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,     3,  8914,  ...,     0,     0,     0],\n",
      "        [32100, 16819,  1177,  ...,     0,     0,     0],\n",
      "        [32100,   283,  1872,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.7670,  3.7855,  2.3133,  ..., -3.8382, -3.6234, -2.2776],\n",
      "        [ 5.1945,  3.9051,  2.3851,  ..., -4.0684, -3.9316, -2.6035],\n",
      "        [ 5.2247,  3.8202,  2.3085,  ..., -3.9961, -3.9245, -2.4704],\n",
      "        ...,\n",
      "        [ 9.0903,  3.5849,  1.0608,  ..., -3.8202, -3.1800, -3.0122],\n",
      "        [ 9.0935,  3.5804,  1.0530,  ..., -3.8498, -3.0856, -3.1078],\n",
      "        [ 9.0975,  3.6539,  0.9495,  ..., -3.8094, -3.2106, -3.1795]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 878, 7465, 1505,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:29,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1122,   404,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     3,  6975,     1],\n",
      "        [32100,  2513,    67,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,    86,    74,  ...,     0,     0,     0],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        [32100,   316,   181,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.3963,  4.2332,  2.1908,  ..., -4.0575, -3.6965, -2.3864],\n",
      "        [ 5.6750,  4.1448,  2.2943,  ..., -4.2477, -4.0792, -2.7113],\n",
      "        [ 5.5553,  4.0795,  2.3251,  ..., -4.3236, -3.9822, -2.7049],\n",
      "        ...,\n",
      "        [ 9.1532,  3.9891,  1.0370,  ..., -4.0917, -3.2752, -3.1799],\n",
      "        [ 9.1065,  4.0611,  1.0756,  ..., -4.0958, -3.3098, -3.0462],\n",
      "        [ 9.1827,  3.9745,  1.0888,  ..., -3.9465, -3.3253, -3.1945]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1122,  404,  256,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:30,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,    86, 20878,  ...,    96, 18077,     1],\n",
      "        [32100,  9654,     3,  ...,     0,     0,     0],\n",
      "        [32100,     3,  9446,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  2432,   528,  ...,    46,  7761,     1],\n",
      "        [32100,  2167,     7,  ..., 18847,     7,     1],\n",
      "        [32100,    86,  3494,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.7779,  3.8302,  2.2282,  ..., -3.9452, -3.7108, -2.2873],\n",
      "        [ 5.1684,  4.0360,  2.3121,  ..., -4.1538, -3.9365, -2.4773],\n",
      "        [ 5.3750,  4.1686,  2.4425,  ..., -4.0004, -4.0606, -2.6062],\n",
      "        ...,\n",
      "        [ 9.1586,  4.4057,  1.2700,  ..., -4.0719, -3.5046, -3.1686],\n",
      "        [ 9.1675,  4.3235,  1.2228,  ..., -4.0434, -3.5113, -3.2078],\n",
      "        [ 9.1721,  4.3037,  1.2603,  ..., -4.1568, -3.4298, -3.1904]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([   86, 20878,    56,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:31,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  7217,   558,  ...,     0,     0,     0],\n",
      "        [32100,   264,     3,  ...,     0,     0,     0],\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  2010,  ...,     0,     0,     0],\n",
      "        [32100,     3, 24370,  ...,    74,    35,     1],\n",
      "        [32100,  1318,  5959,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8800,  4.0534,  2.0928,  ..., -3.9779, -3.6457, -2.1409],\n",
      "        [ 5.3230,  3.8765,  2.1273,  ..., -4.1429, -4.0154, -2.5758],\n",
      "        [ 5.2606,  3.9760,  2.0803,  ..., -3.9787, -3.9556, -2.5194],\n",
      "        ...,\n",
      "        [ 7.8963,  5.6286,  2.1192,  ..., -4.7552, -4.1588, -3.2350],\n",
      "        [ 8.5549,  5.4859,  1.8136,  ..., -4.5756, -4.0824, -3.2222],\n",
      "        [ 8.9887,  4.9404,  1.6260,  ..., -4.3006, -3.8051, -3.2568]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([7217,  558,  745,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:31,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   325,  4932,  ...,    29,  6056,     1],\n",
      "        [32100,   679,    77,  ...,     0,     0,     0],\n",
      "        [32100,  1122,   615,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  8083,   595,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,     3,  8914,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9057,  3.9018,  2.3402,  ..., -3.9807, -3.6552, -2.2433],\n",
      "        [ 5.0873,  3.9660,  2.2620,  ..., -4.1349, -3.8542, -2.4688],\n",
      "        [ 5.1769,  3.8578,  2.3044,  ..., -3.8394, -4.0408, -2.6946],\n",
      "        ...,\n",
      "        [ 9.0639,  4.7906,  1.3753,  ..., -4.3100, -3.6268, -3.2412],\n",
      "        [ 9.0811,  4.6096,  1.4774,  ..., -4.0116, -3.6444, -3.2406],\n",
      "        [ 9.0544,  4.7884,  1.4299,  ..., -4.2786, -3.6631, -3.2492]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 325, 4932,  292,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:32,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,    86,   177,  ...,     0,     0,     0],\n",
      "        [32100,  1122,   229,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1122,  9852,  ...,     0,     0,     0],\n",
      "        [32100,  1185,  6905,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.7441,  3.8898,  2.3323,  ..., -3.8428, -3.8045, -2.3056],\n",
      "        [ 5.4898,  4.1876,  2.3697,  ..., -4.0808, -4.0006, -2.7424],\n",
      "        [ 5.4457,  3.8997,  2.2394,  ..., -4.1743, -3.9646, -2.5583],\n",
      "        ...,\n",
      "        [ 9.0881,  4.4521,  1.3378,  ..., -4.0728, -3.4932, -3.1930],\n",
      "        [ 9.1512,  4.5836,  1.3034,  ..., -4.0964, -3.4914, -3.3023],\n",
      "        [ 9.1511,  4.5614,  1.3724,  ..., -4.1944, -3.5881, -3.2371]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 86, 177,   3,  ...,   0,   0,   0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54it [00:33,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  9654,   229,  ...,     0,     0,     0],\n",
      "        [32100,  1821,   177,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  4098,   319,  ...,     0,     0,     0],\n",
      "        [32100,   316,  7672,  ...,     0,     0,     0],\n",
      "        [32100,   660, 14691,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.7740,  4.3868,  2.0656,  ..., -4.3322, -3.4839, -2.3194],\n",
      "        [ 5.5407,  4.1333,  2.2653,  ..., -4.3231, -4.0381, -2.7444],\n",
      "        [ 5.2983,  4.0282,  2.0910,  ..., -4.1844, -3.8464, -2.6194],\n",
      "        ...,\n",
      "        [ 9.1639,  4.2936,  1.2212,  ..., -4.1749, -3.4268, -3.0916],\n",
      "        [ 9.1746,  4.4409,  1.3061,  ..., -4.0907, -3.5538, -3.2380],\n",
      "        [ 9.1646,  4.4256,  1.2394,  ..., -4.1918, -3.5328, -3.1554]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([9654,  229,    3,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [00:33,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  9654,  4186,  ...,     0,     0,     0],\n",
      "        [32100,  1185,   436,  ...,     0,     0,     0],\n",
      "        [32100,     3,  8914,  ...,  9717,     5,     1],\n",
      "        ...,\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,   309, 12120,  ...,     0,     0,     0],\n",
      "        [32100,  1318,   426,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.2521,  4.4181,  2.0501,  ..., -4.1696, -3.3805, -2.1083],\n",
      "        [ 5.4698,  4.2560,  2.1223,  ..., -4.0475, -3.8602, -2.7211],\n",
      "        [ 5.3565,  4.2349,  2.0286,  ..., -4.3056, -3.8865, -2.6534],\n",
      "        ...,\n",
      "        [ 9.1652,  4.3203,  1.3321,  ..., -4.1551, -3.5360, -3.0720],\n",
      "        [ 9.1911,  4.3478,  1.1668,  ..., -4.1438, -3.4747, -3.2132],\n",
      "        [ 9.1742,  4.4745,  1.2048,  ..., -4.1017, -3.5418, -3.0899]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([9654, 4186,   74,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:34,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1122,  5282,  ...,     0,     0,     0],\n",
      "        [32100,   316,   180,  ...,    35,   218,     1],\n",
      "        [32100,   316, 10122,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316, 19071,  ...,    53,    15,     1],\n",
      "        [32100,   292,   436,  ...,     0,     0,     0],\n",
      "        [32100, 10127,    15,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1584,  4.2697,  2.0395,  ..., -4.1791, -3.6610, -2.3032],\n",
      "        [ 5.4101,  4.0167,  2.4127,  ..., -3.9738, -3.9782, -2.7444],\n",
      "        [ 5.9612,  4.2474,  2.2294,  ..., -4.4225, -4.1347, -2.8925],\n",
      "        ...,\n",
      "        [ 9.1920,  4.3171,  1.3408,  ..., -4.1243, -3.4319, -3.2262],\n",
      "        [ 9.1378,  4.6113,  1.2220,  ..., -4.1946, -3.5859, -3.2253],\n",
      "        [ 9.1538,  4.4852,  1.3907,  ..., -4.1134, -3.4772, -3.1581]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1122, 5282,  319,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:34,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 18843, 15402,  ...,     0,     0,     0],\n",
      "        [32100, 30676,    29,  ...,     0,     0,     0],\n",
      "        [32100,   316, 15402,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   389, 30227,  ...,  8078,   425,     1],\n",
      "        [32100, 17909,    74,  ...,     0,     0,     0],\n",
      "        [32100,     3, 13392,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.9453,  4.7315,  2.0496,  ..., -4.2324, -3.4576, -2.2247],\n",
      "        [ 5.8566,  4.2468,  2.0842,  ..., -4.2974, -3.9839, -2.7767],\n",
      "        [ 6.0746,  4.6476,  2.0744,  ..., -4.4575, -4.1040, -2.7751],\n",
      "        ...,\n",
      "        [ 9.1648,  4.0259,  1.1451,  ..., -4.0764, -3.2532, -3.2364],\n",
      "        [ 9.1686,  4.1624,  1.1958,  ..., -4.1661, -3.3620, -3.1410],\n",
      "        [ 9.1775,  4.1117,  1.1077,  ..., -4.1032, -3.3197, -3.1422]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([18843, 15402,  6973,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [00:35,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   480, 17309,  ...,     0,     0,     0],\n",
      "        [32100,   316, 11726,  ...,     0,     0,     0],\n",
      "        [32100,  1985,   645,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  8816,  5837,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9437,  4.0591,  2.4034,  ..., -4.0617, -3.5472, -2.2479],\n",
      "        [ 5.7111,  4.5131,  2.2232,  ..., -4.2276, -3.9159, -2.6091],\n",
      "        [ 5.7595,  4.3143,  2.3424,  ..., -4.1966, -3.9670, -2.7156],\n",
      "        ...,\n",
      "        [ 9.1917,  4.2942,  1.2977,  ..., -4.1197, -3.3886, -3.0952],\n",
      "        [ 9.1473,  4.6112,  1.3481,  ..., -4.2749, -3.5062, -3.2067],\n",
      "        [ 9.1959,  4.3320,  1.2661,  ..., -4.1233, -3.6285, -3.2238]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  480, 17309,   551,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:36,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 13848,    15,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ..., 19146,   170,     1],\n",
      "        [32100,  1122,   229,  ..., 17568, 10133,     1],\n",
      "        ...,\n",
      "        [32100,   848,     3,  ...,  8579,     6,     1],\n",
      "        [32100,  9654, 13411,  ...,     0,     0,     0],\n",
      "        [32100,  9654,   551,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1322,  4.1735,  2.1959,  ..., -4.0457, -3.3262, -2.1586],\n",
      "        [ 5.3079,  4.4251,  2.2213,  ..., -4.3347, -3.9552, -2.5815],\n",
      "        [ 5.4070,  4.1134,  2.2573,  ..., -4.1583, -3.9714, -2.5986],\n",
      "        ...,\n",
      "        [ 9.1811,  4.1486,  1.1748,  ..., -4.0532, -3.3159, -3.2753],\n",
      "        [ 9.2057,  4.1207,  1.2101,  ..., -4.0310, -3.3050, -3.0862],\n",
      "        [ 9.1870,  4.0758,  1.1983,  ..., -3.9702, -3.2692, -3.0971]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([13848,    15,   961,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:36,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  1674,  6509,  ...,     5,     1,     0],\n",
      "        [32100,  1392,   637,  ...,   266,     7,     1],\n",
      "        [32100,  1674,  2701,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  7838,  ...,  9143,   229,     1],\n",
      "        [32100,  1122,  3015,  ...,     0,     0,     0],\n",
      "        [32100,  1122,   551,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9525,  3.9347,  2.1630,  ..., -3.9228, -3.8612, -2.4285],\n",
      "        [ 5.3605,  4.0684,  2.2463,  ..., -4.1417, -3.9772, -2.4909],\n",
      "        [ 5.1926,  3.9040,  2.3659,  ..., -4.0584, -3.9209, -2.5194],\n",
      "        ...,\n",
      "        [ 9.1806,  4.4232,  1.2963,  ..., -4.0889, -3.5221, -3.1833],\n",
      "        [ 9.1796,  4.5004,  1.3667,  ..., -4.2391, -3.5336, -3.1256],\n",
      "        [ 9.1704,  4.4406,  1.3480,  ..., -4.1053, -3.6648, -3.2066]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([1674, 6509,    3,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [00:37,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 19399,   193,  ...,     0,     0,     0],\n",
      "        [32100,  8816,  6455,  ..., 14897,   426,     1],\n",
      "        [32100,     3,  9446,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   292,   436,  ...,     0,     0,     0],\n",
      "        [32100,   432,  1000,  ...,     0,     0,     0],\n",
      "        [32100,  1185,     3,  ...,  7955,   730,     1]], device='cuda:0')\n",
      "tensor([[ 5.2391,  4.5173,  2.0146,  ..., -4.1529, -3.6153, -2.1544],\n",
      "        [ 5.5367,  4.1461,  2.2075,  ..., -4.1138, -3.9563, -2.6076],\n",
      "        [ 5.5793,  3.9915,  2.0385,  ..., -4.2248, -4.0217, -2.6616],\n",
      "        ...,\n",
      "        [ 7.9459,  5.6874,  2.1315,  ..., -4.6110, -4.3053, -3.1903],\n",
      "        [ 7.6141,  5.6095,  2.1680,  ..., -4.6325, -4.2279, -2.9931],\n",
      "        [ 8.0492,  5.4069,  1.9769,  ..., -4.7199, -4.3007, -3.1950]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([19399,   193,  1149,  ...,   730,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   878,   760,  ...,     0,     0,     0],\n",
      "        [32100,    71, 29655,  ...,  3818,   219,     1],\n",
      "        [32100,   644,   229,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  9235,    17,  ...,   181,   637,     1],\n",
      "        [32100,  1674, 18946,  ...,     0,     0,     0],\n",
      "        [32100,   644,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9785,  4.0871,  2.2707,  ..., -3.8278, -3.8958, -2.4721],\n",
      "        [ 5.2259,  4.0612,  2.3360,  ..., -4.0582, -3.8884, -2.5064],\n",
      "        [ 5.8014,  4.3234,  2.2627,  ..., -4.1808, -4.1424, -2.7892],\n",
      "        ...,\n",
      "        [ 9.1075,  3.6884,  0.9933,  ..., -4.0133, -3.1785, -3.2321],\n",
      "        [ 9.1237,  3.6702,  1.0524,  ..., -3.8530, -3.0572, -3.1097],\n",
      "        [ 9.1689,  3.9782,  1.2103,  ..., -4.0551, -3.2111, -3.1181]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([878, 760,  21,  ...,   0,   0,   0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:38,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   878,     3,  ...,    35,     6,     1],\n",
      "        [32100,   374, 14737,  ...,     6,    67,     1],\n",
      "        [32100, 17919,   122,  ...,   209,    64,     1],\n",
      "        ...,\n",
      "        [32100,  1185,   404,  ...,  2029,    23,     1],\n",
      "        [32100, 18843,    29,  ...,     0,     0,     0],\n",
      "        [32100,  2751,    67,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.7003,  3.9185,  2.3290,  ..., -3.9336, -3.7124, -2.3596],\n",
      "        [ 5.2404,  4.2070,  2.3554,  ..., -4.0072, -4.0200, -2.4843],\n",
      "        [ 5.0066,  3.8182,  2.2904,  ..., -4.0705, -3.9905, -2.5443],\n",
      "        ...,\n",
      "        [ 8.8753,  5.2810,  1.6851,  ..., -4.3206, -3.9836, -3.3306],\n",
      "        [ 8.8520,  5.2894,  1.7292,  ..., -4.5712, -3.9205, -3.2122],\n",
      "        [ 8.8491,  5.2946,  1.5804,  ..., -4.4670, -3.8542, -3.3465]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([878,   3,   9,  ...,   0,   0,   0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   325,  4932,  ...,     0,     0,     0],\n",
      "        [32100,  1318,  2522,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1185,  3766,  ...,     0,     0,     0],\n",
      "        [32100,  7680,  9711,  ...,     0,     0,     0],\n",
      "        [32100, 11565,   436,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.8306,  3.8472,  2.1409,  ..., -4.1692, -3.6771, -2.2523],\n",
      "        [ 5.5495,  4.3629,  2.4161,  ..., -4.0880, -4.0048, -2.7202],\n",
      "        [ 5.1930,  3.8337,  2.2414,  ..., -4.1156, -3.9799, -2.6147],\n",
      "        ...,\n",
      "        [ 9.2051,  3.9184,  1.2791,  ..., -4.0309, -3.3978, -3.1897],\n",
      "        [ 9.2001,  3.9721,  1.1700,  ..., -3.9729, -3.3492, -3.1903],\n",
      "        [ 9.2048,  4.0539,  1.1736,  ..., -4.1251, -3.3150, -2.9959]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 325, 4932,  292,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:39,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100, 18843,  6973,  ...,   193,  5512,     1],\n",
      "        [32100,  2973, 10606,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  2701,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  7077, 17391,  ...,     0,     0,     0],\n",
      "        [32100,   316,  1226,  ...,     9,  9256,     1],\n",
      "        [32100,   961, 31552,  ...,   157,  1411,     1]], device='cuda:0')\n",
      "tensor([[ 4.8039,  3.7789,  2.4285,  ..., -3.9126, -3.9031, -2.5484],\n",
      "        [ 5.1860,  3.9961,  2.3449,  ..., -4.0784, -3.8686, -2.5583],\n",
      "        [ 5.4501,  3.9958,  2.2041,  ..., -4.0070, -4.0169, -2.6615],\n",
      "        ...,\n",
      "        [ 8.3034,  5.6222,  1.9894,  ..., -4.7400, -4.1686, -3.2339],\n",
      "        [ 8.5829,  5.5339,  1.9323,  ..., -4.6515, -4.0286, -3.2305],\n",
      "        [ 8.5910,  5.5746,  1.8835,  ..., -4.6246, -4.0612, -3.1780]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([18843,  6973,     6,  ...,  1411,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:40,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   644,  7106,  ...,     0,     0,     0],\n",
      "        [32100,     3, 16239,  ...,     0,     0,     0],\n",
      "        [32100,  1318, 25349,  ...,    74, 10122,     1],\n",
      "        ...,\n",
      "        [32100,  1122,   229,  ...,     0,     0,     0],\n",
      "        [32100,   389, 30227,  ...,   637,  3983,     1],\n",
      "        [32100,  1185,   745,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9644,  4.1266,  2.3669,  ..., -3.9658, -3.6543, -2.0339],\n",
      "        [ 5.5034,  4.0968,  2.3340,  ..., -4.1327, -4.0078, -2.5709],\n",
      "        [ 5.6085,  4.3884,  2.2390,  ..., -4.2653, -3.9510, -2.6199],\n",
      "        ...,\n",
      "        [ 9.1850,  4.3751,  1.3830,  ..., -4.0659, -3.3893, -3.1209],\n",
      "        [ 9.2180,  4.3286,  1.2233,  ..., -4.0834, -3.5106, -3.2217],\n",
      "        [ 9.2186,  4.1784,  1.3184,  ..., -4.1258, -3.4739, -3.0967]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 644, 7106,  229,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:40,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   325,  4932,  ...,     0,     0,     0],\n",
      "        [32100,  1662,   637,  ...,     0,     0,     0],\n",
      "        [32100, 12597,   436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316,  5524,  ...,     0,     0,     0],\n",
      "        [32100,   316,  3333,  ...,     3, 20497,     1],\n",
      "        [32100,  9235,    17,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 5.1151,  4.2121,  2.3997,  ..., -4.1473, -3.6828, -2.2037],\n",
      "        [ 5.8292,  4.3801,  2.2796,  ..., -4.2594, -4.2577, -2.8552],\n",
      "        [ 5.4075,  3.9655,  2.2445,  ..., -4.1634, -4.1263, -2.6642],\n",
      "        ...,\n",
      "        [ 9.1975,  4.3331,  1.3145,  ..., -4.2088, -3.5174, -3.1481],\n",
      "        [ 9.2240,  4.3007,  1.1455,  ..., -4.0738, -3.4330, -3.1766],\n",
      "        [ 9.2149,  4.2358,  1.1217,  ..., -4.1213, -3.3463, -3.2076]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 325, 4932,  292,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:41,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316, 12390,  ..., 15560,    93,     1],\n",
      "        [32100,   316,     3,  ..., 30941,    35,     1],\n",
      "        [32100,  1674,  6509,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,    86,    74,  ...,     0,     0,     0],\n",
      "        [32100, 11280,   324,  ...,     0,     0,     0],\n",
      "        [32100, 23371,   637,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.6747,  3.9281,  2.3209,  ..., -4.0177, -3.6664, -2.2322],\n",
      "        [ 5.5149,  4.1000,  2.2922,  ..., -3.9906, -4.2509, -2.6218],\n",
      "        [ 5.0202,  3.8470,  2.4568,  ..., -3.9343, -3.8370, -2.5514],\n",
      "        ...,\n",
      "        [ 9.1958,  3.8597,  1.1422,  ..., -3.9083, -3.2142, -3.2606],\n",
      "        [ 9.2255,  4.0269,  1.2008,  ..., -4.0929, -3.2719, -3.0604],\n",
      "        [ 9.2167,  3.8754,  1.1056,  ..., -4.0233, -3.3156, -3.0600]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  316, 12390,    35,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:42,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316, 25711,  ...,  2043,   109,     1],\n",
      "        [32100,  1185,  6199,  ...,     0,     0,     0],\n",
      "        [32100,  1318,   426,  ...,  4847,  5837,     1],\n",
      "        ...,\n",
      "        [32100,  8816, 11314,  ...,     0,     0,     0],\n",
      "        [32100,    86,  2352,  ...,     0,     0,     0],\n",
      "        [32100,  8816,     3,  ...,     3, 11139,     1]], device='cuda:0')\n",
      "tensor([[ 4.8031,  3.8079,  2.0827,  ..., -4.0001, -3.7083, -2.3181],\n",
      "        [ 5.2538,  3.9145,  2.1300,  ..., -3.9900, -4.0061, -2.5140],\n",
      "        [ 5.0919,  3.8846,  2.2175,  ..., -3.9654, -3.9867, -2.5580],\n",
      "        ...,\n",
      "        [ 8.5252,  5.5571,  1.7042,  ..., -4.4327, -4.1550, -3.2142],\n",
      "        [ 8.5617,  5.6220,  1.7062,  ..., -4.4734, -3.9720, -3.1302],\n",
      "        [ 8.9106,  5.2190,  1.5142,  ..., -4.5633, -3.9196, -3.3262]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([  316, 25711,     7,  ..., 11139,     1,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:42,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,  7957,  ...,     0,     0,     0],\n",
      "        [32100,  1674,  6509,  ...,     1,     0,     0],\n",
      "        [32100,  1311,   645,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,   316, 15464,  ...,  1811, 13807,     1],\n",
      "        [32100,  7672,     3,  ...,     0,     0,     0],\n",
      "        [32100,   316,  8787,  ..., 23851,    88,     1]], device='cuda:0')\n",
      "tensor([[ 5.7169,  4.5419,  1.9734,  ..., -4.3808, -3.5227, -2.1870],\n",
      "        [ 5.8115,  4.4399,  2.1788,  ..., -4.1738, -4.1451, -2.7496],\n",
      "        [ 5.8710,  4.5204,  2.2252,  ..., -4.2801, -4.2010, -2.8854],\n",
      "        ...,\n",
      "        [ 5.8348,  4.3400,  2.4492,  ..., -4.1215, -4.2091, -2.8398],\n",
      "        [ 6.3367,  4.6678,  2.5017,  ..., -4.3689, -4.2972, -2.7694],\n",
      "        [ 8.5096,  5.4798,  1.8033,  ..., -4.5930, -4.1081, -3.1869]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 316, 7957,  193,  ...,   88,    1,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:43,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  8933,  4994,  ...,     0,     0,     0],\n",
      "        [32100,  1674,     3,  ...,   425,  9003,     1],\n",
      "        [32100,   325,  4932,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  2751,     3,  ...,     0,     0,     0],\n",
      "        [32100,  2167,   493,  ...,     0,     0,     0],\n",
      "        [32100,  1674,    36,  ...,     9,   235,     1]], device='cuda:0')\n",
      "tensor([[ 4.6892,  3.6702,  2.1956,  ..., -3.8775, -3.5674, -2.2881],\n",
      "        [ 5.1603,  3.8088,  2.3845,  ..., -4.1381, -4.0730, -2.6532],\n",
      "        [ 5.3604,  3.9850,  2.1438,  ..., -4.1272, -3.9706, -2.8555],\n",
      "        ...,\n",
      "        [ 8.1883,  5.6390,  1.9211,  ..., -4.6747, -4.3232, -3.2538],\n",
      "        [ 8.9848,  5.2331,  1.5469,  ..., -4.3594, -3.8898, -3.3825],\n",
      "        [ 8.9874,  5.2520,  1.5866,  ..., -4.4908, -3.9745, -3.2807]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([8933, 4994,  229,  ...,  235,    1,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:43,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,  8816,     3,  ...,     1,     0,     0],\n",
      "        [32100,  7217,    67,  ...,     0,     0,     0],\n",
      "        [32100,   316,     3,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  4444, 16282,  ...,   548, 13832,     1],\n",
      "        [32100,  8083,  1284,  ...,     0,     0,     0],\n",
      "        [32100,   292,  9225,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.6295,  3.7554,  2.2925,  ..., -4.0064, -3.8563, -2.3085],\n",
      "        [ 5.2418,  3.8568,  2.3523,  ..., -4.0717, -3.9510, -2.5255],\n",
      "        [ 5.2611,  4.0679,  2.2242,  ..., -4.0199, -3.9991, -2.6159],\n",
      "        ...,\n",
      "        [ 9.1701,  4.1016,  1.0673,  ..., -3.9515, -3.2901, -3.0149],\n",
      "        [ 9.2201,  3.8656,  1.0014,  ..., -3.9686, -3.3424, -3.2236],\n",
      "        [ 9.1970,  4.1141,  1.2417,  ..., -3.9849, -3.3441, -3.0418]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 8816,     3, 20962,  ...,     0,     0,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:44,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   264,  3015,  ...,     0,     0,     0],\n",
      "        [32100,  1821,    74,  ...,     0,     0,     0],\n",
      "        [32100, 21539,     7,  ...,  9902,   755,     1],\n",
      "        ...,\n",
      "        [32100,  4455,     6,  ...,     0,     0,     0],\n",
      "        [32100,     3,     2,  ...,     0,     0,     0],\n",
      "        [32100,   316,    36,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.9168,  3.8432,  2.3639,  ..., -4.0091, -3.8565, -2.3460],\n",
      "        [ 5.3748,  3.9666,  2.1359,  ..., -4.3459, -4.0225, -2.7148],\n",
      "        [ 5.4182,  4.0479,  2.3722,  ..., -4.1376, -4.1312, -2.7621],\n",
      "        ...,\n",
      "        [ 9.0977,  5.0937,  1.5428,  ..., -4.3524, -3.8321, -3.2984],\n",
      "        [ 8.7119,  5.5008,  1.6099,  ..., -4.6352, -4.0264, -3.0852],\n",
      "        [ 9.1968,  4.5939,  1.3106,  ..., -4.2884, -3.6441, -3.2503]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([ 264, 3015,    3,  ...,    0,    0,    0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [00:45,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[32100,   316,    96,  ...,     0,     0,     0],\n",
      "        [32100,   660,  1526,  ...,     0,     0,     0],\n",
      "        [32100, 12125,     7,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [32100,  1674,  2010,  ...,     0,     0,     0],\n",
      "        [32100,   325,  4932,  ...,     0,     0,     0],\n",
      "        [32100,   890,  2974,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[ 4.6945,  3.8397,  2.2407,  ..., -4.0904, -3.7931, -2.1687],\n",
      "        [ 5.1553,  3.8111,  2.2010,  ..., -4.1295, -3.9708, -2.6296],\n",
      "        [ 5.0897,  3.7585,  2.1678,  ..., -4.1094, -3.9430, -2.4499],\n",
      "        ...,\n",
      "        [ 8.9125,  5.2519,  1.4627,  ..., -4.6069, -4.0883, -3.3687],\n",
      "        [ 8.7528,  5.5159,  1.8092,  ..., -4.5893, -3.9517, -3.3188],\n",
      "        [ 8.4207,  5.6979,  1.9928,  ..., -4.5949, -4.2065, -3.2550]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "tensor([316,  96, 517,  ...,   0,   0,   0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [00:46,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 19\u001b[0m\n\u001b[0;32m     13\u001b[0m english_batch \u001b[38;5;241m=\u001b[39m english_batch\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m     14\u001b[0m german_batch \u001b[38;5;241m=\u001b[39m german_batch\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 19\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43menglish_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgerman_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, target_vocab_dim)\n\u001b[0;32m     21\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m english_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Project-Polaris\\Project-Polaris\\Transformer\\transformer.py:121\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, source, target)\u001b[0m\n\u001b[0;32m    117\u001b[0m target_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_mask(target)\n\u001b[0;32m    119\u001b[0m cross_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_cross_attention_mask(source, target)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Project-Polaris\\Project-Polaris\\Transformer\\decoder.py:73\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, encoder_output, mask, cross_attention_mask)\u001b[0m\n\u001b[0;32m     70\u001b[0m inputTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_layer(inputTensor)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_blocks:\n\u001b[1;32m---> 73\u001b[0m     inputTensor \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_attention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m inputTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(inputTensor)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# return F.softmax(inputTensor, dim = -1)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Project-Polaris\\Project-Polaris\\Transformer\\decoder_block.py:69\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, decoder_key, decoder_query, decoder_value, encoder_key, encoder_query, encoder_value, mask, padding_mask, cross_attention_mask)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, decoder_key : torch\u001b[38;5;241m.\u001b[39mTensor, decoder_query : torch\u001b[38;5;241m.\u001b[39mTensor, decoder_value : torch\u001b[38;5;241m.\u001b[39mTensor, encoder_key : torch\u001b[38;5;241m.\u001b[39mTensor, encoder_query : torch\u001b[38;5;241m.\u001b[39mTensor, encoder_value : torch\u001b[38;5;241m.\u001b[39mTensor, mask : torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, padding_mask : torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, cross_attention_mask : torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Receives as input:\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     selfAttentionOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselfAttentionLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     attentionDropoutResNorm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirstLayerNorm(decoder_value \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(selfAttentionOutput))\n\u001b[0;32m     73\u001b[0m     crossAttentionOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoderBlock(encoder_key, attentionDropoutResNorm, encoder_value, \u001b[38;5;28;01mNone\u001b[39;00m, cross_attention_mask)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Project-Polaris\\Project-Polaris\\Transformer\\multi_head_attention.py:91\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, key, query, value, mask, padding_mask)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     attention_mask[padding_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;241m/\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# The result will be [batch_size, no_heads, seq_len_query, seq_len]\u001b[39;00m\n\u001b[0;32m     93\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(attention_mask, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#Normalizing on the columns\u001b[39;00m\n\u001b[0;32m     95\u001b[0m val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attention_mask, v) \u001b[38;5;66;03m# [batch_size, no_heads, seq_len_query, split_size]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    train_loss = 0\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(train_dataloader)):\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        english_batch, german_batch = batch\n",
    "        english_batch = english_batch.long().cuda()\n",
    "        german_batch = german_batch.long().cuda()\n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "        pred = model(english_batch, german_batch)\n",
    "        pred = pred.view(-1, target_vocab_dim)\n",
    "        batch_size = english_batch.shape[0]\n",
    "        #print(pred.shape)\n",
    "        target = german_batch[:, 1:]\n",
    "        \n",
    "        #print(pred.shape)\n",
    "        added = torch.zeros(batch_size, 1).cuda()\n",
    " \n",
    "        target = torch.cat([target, added], dim = 1)\n",
    "\n",
    "        target = target.view(-1).long()\n",
    "\n",
    "        #print(german_batch)\n",
    "        #print(pred) \n",
    "        #print(target)\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        torch.save(model.state_dict(), f'checkpoints/model_parameters_2M_{e}.pth')\n",
    "\n",
    "    print(f\"The train loss on epoch {e} is {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d86d0e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\3508264477.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('checkpoints/model_parameters_2M_4.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/model_parameters_2M_4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb44265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.mkdir(\"checkpoints\")\n",
    "\n",
    "# torch.save(model.state_dict(), 'checkpoints/model_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20170417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    x = DatasetClass(dataset, \"test\")\n",
    "    english_text = x.applyEnglishTokenizer(text).unsqueeze(0).long().cuda()\n",
    "    #print(model.decode(64,english_text))\n",
    "    t = list(model.decode(64, english_text)[0].cpu().numpy())\n",
    "    print(t)\n",
    "    print([y for y in t])\n",
    "    return [x.english_tokenizer.convert_ids_to_tokens(int(y)) for y in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d45fd2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.english_texts = torch.load(f\"./SavedData/{partition}/en.pth\")\n",
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Temp\\ipykernel_34136\\1673923592.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.german_texts = torch.load(f\"./SavedData/{partition}/de.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32100, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[32100, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[None, '', '<pad>', '<pad>', '<pad>', '<pad>', '', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(translate(\"yOU ARE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_tokenizer.convert_tokens_to_ids(\"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_tokenizer.add_special_tokens({'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'})\n",
    "\n",
    "print(german_tokenizer.special_tokens_map)\n",
    "print(german_tokenizer.convert_ids_to_tokens(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74694db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfff39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8d39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6e5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18eade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550aa598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca51a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4a897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296c598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358121ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4fbff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token_id = english_tokenizer.convert_tokens_to_ids('<s>')\n",
    "eos_token_id = english_tokenizer.convert_tokens_to_ids('</s>')\n",
    "print(bos_token_id, eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde85023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad03fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7b2ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
