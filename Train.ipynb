{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726d0584-1778-43c0-93dd-a1e174e10255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from GPT.gptForUnsupervisedTraining import GPTForUnsupervisedTraining\n",
    "from GPT.gptDecoder import GPTDecoder\n",
    "from transformers import GPT2Tokenizer, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172c2a2-aebc-4d84-8c0e-e4dda043cb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b346fb-e3bd-4a65-bdd3-771df7bc4e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTDecoder(\n",
      "  (decoder_stack): ModuleList(\n",
      "    (0-5): 6 x DecoderBlock(\n",
      "      (selfAttentionLayer): MultiHeadAttention(\n",
      "        (WQuery): Linear(in_features=384, out_features=384, bias=False)\n",
      "        (WKey): Linear(in_features=384, out_features=384, bias=False)\n",
      "        (WValue): Linear(in_features=384, out_features=384, bias=False)\n",
      "        (WOut): Linear(in_features=384, out_features=384, bias=True)\n",
      "      )\n",
      "      (firstLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (secondLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc): Sequential(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (dropoutLayer): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (embedding_layer): EmbeddingLayer(\n",
      "    (model): Embedding(45000, 384, padding_idx=0)\n",
      "  )\n",
      "  (positional_embedder): PositionalEncoder()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model = GPTDecoder(seq_len = 64, target_vocab_size = 45000, embedding_dim = 384, no_heads = 6, no_decoder_blocks = 6)\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fef19c-820c-4a2b-bc7b-77b8e01f1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTForUnsupervisedTraining(base_model, vocab_size = 45000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4bdc71-9ec6-43ca-b32c-926d2eb86d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token: <unk>, Pad token ID: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ionut Anghelina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/openai-gpt')\n",
    "\n",
    "# Set the pad token as a placeholder with a token ID of 0\n",
    "tokenizer.pad_token = '[PAD]'  # This can be any string, it's just a placeholder token\n",
    "\n",
    "# Assign 0 as the pad_token_id\n",
    "tokenizer.pad_token_id = 0\n",
    "\n",
    "#print(tokenizer.decode([0]))\n",
    "\n",
    "# Verify pad_token_id is now set to 0\n",
    "print(f\"Pad token: {tokenizer.pad_token}, Pad token ID: {tokenizer.pad_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2b087d-06f7-4b46-9be2-191dc19c79ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\\n\".join(open(r\"Kanye West Lyrics.txt\",\"r\",encoding = 'utf-8').readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac3b4a2-d0a6-45ca-b39b-3ead04e9540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (94807 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b299b94-cedd-428a-8c07-d888ef936ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6199779-9ec2-4d7e-92ad-903a2b1b4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9f93e0-7381-405c-b85a-e1f4a670da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94807\n",
      "40411\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(max(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e291b1-2af4-46ab-93de-d20d17ed307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(tokens), 64):\n",
    "\n",
    "    input = tokens[i:i+model.baseModel.seq_len]\n",
    "    target = tokens[i+1:i+model.baseModel.seq_len+1]\n",
    "\n",
    "    if len(input) < model.baseModel.seq_len:\n",
    "        input = input + [0] * (model.baseModel.seq_len - len(input))\n",
    "\n",
    "    if len(target) < model.baseModel.seq_len:\n",
    "        target = target + [0] * (model.baseModel.seq_len - len(target))\n",
    "\n",
    "    input = torch.Tensor(input).long()\n",
    "    target = torch.Tensor(target).long()\n",
    "\n",
    "    #print(input)\n",
    "    #print(target)\n",
    "    inputs.append(input)\n",
    "    targets.append(target)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f78460-0408-4e68-9377-3f44a746c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.cat([x.unsqueeze(0) for x in inputs], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ff344d-5911-47d6-bfdc-118c11b32a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1482, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92fa48f-a842-4c79-8a36-57336e8fd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.cat([x.unsqueeze(0) for x in targets], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e913e8-b5d1-4b26-8fcd-7bfdacb4d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs, targets)\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24259e52-9697-4eb0-b3e7-8969018e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b42a9c06-a89e-4cba-afed-d20e20f53d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTForUnsupervisedTraining(\n",
       "  (baseModel): GPTDecoder(\n",
       "    (decoder_stack): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (selfAttentionLayer): MultiHeadAttention(\n",
       "          (WQuery): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WKey): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WValue): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WOut): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (firstLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (secondLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropoutLayer): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (embedding_layer): EmbeddingLayer(\n",
       "      (model): Embedding(45000, 384, padding_idx=0)\n",
       "    )\n",
       "    (positional_embedder): PositionalEncoder()\n",
       "  )\n",
       "  (fc): Linear(in_features=384, out_features=45000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ec56bc-739d-4713-adc3-9d1fbad79cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(),lr = 5e-4)\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56ae862d-b125-4e58-8d0b-92ab5fb47404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e6ed7c5-66c3-4973-82be-ff0727d7a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "#loss_fn = torch.nn.CrossEntropyLoss()\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e16305d4-40df-4401-a1d8-3dc25a4c2ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:05,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss from epoch 0 is 7.68636214041356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "\n",
    "    num_samples = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "\n",
    "        model.train()\n",
    "      \n",
    "        \n",
    "        #print(batch)\n",
    "    \n",
    "        inputs, targets = batch\n",
    "    \n",
    "        #print(inputs.device)\n",
    "            \n",
    "        preds = model(inputs)\n",
    "    \n",
    "        preds = preds.view(-1, preds.shape[-1]).to(device)\n",
    "        #print(preds.shape)\n",
    "    \n",
    "        targets = targets.view(-1).to(device)\n",
    "    \n",
    "        #print(targets.shape)\n",
    "        \n",
    "        loss = loss_fn(preds, targets)\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.shape[0]\n",
    "        num_samples += inputs.shape[0]\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "    print(f\"The loss from epoch {e} is {epoch_loss / num_samples}\")\n",
    "          \n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "359d978b-2e6c-4374-95d4-740696dcd8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTForUnsupervisedTraining(\n",
       "  (baseModel): GPTDecoder(\n",
       "    (decoder_stack): ModuleList(\n",
       "      (0-5): 6 x DecoderBlock(\n",
       "        (selfAttentionLayer): MultiHeadAttention(\n",
       "          (WQuery): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WKey): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WValue): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (WOut): Linear(in_features=384, out_features=384, bias=True)\n",
       "        )\n",
       "        (firstLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (secondLayerNorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropoutLayer): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (embedding_layer): EmbeddingLayer(\n",
       "      (model): Embedding(45000, 384, padding_idx=0)\n",
       "    )\n",
       "    (positional_embedder): PositionalEncoder()\n",
       "  )\n",
       "  (fc): Linear(in_features=384, out_features=45000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a305ca8d-c551-4fa5-b1fb-7178a3a062f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(\"Frank Ocean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "583e38cc-4d6f-476f-b26e-5aef8becb3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a71272e-ba95-4616-89d1-1c3708c54eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.decode(target_seq_len = 64 ,inputTensor = torch.Tensor([input]).long(), greedy_decoding = False, temperature = 0.7, show_steps = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22f2052c-7c38-4474-9604-94afbcc9d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4416,  4688,  1531,  1531,   293,  3769,   806,   481,   762,   510,\n",
      "           568,   770,   240,   249,   256,   258,   256,   241,   249,   256,\n",
      "           241,   240,   260,   655,   240,   664,   616,   244,   256,   256,\n",
      "           241,   240,   240,   256,   252,   481,   246,  2441,   481,   249,\n",
      "           256,   241,   488,   249,   256,   241,   581,   240,   599,   256,\n",
      "           241,   649,   246,   788,   240,   485,   481, 21908,   256,   241,\n",
      "           507,   256,   241,   768]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71481bb5-394c-4781-997f-5eca0c6fb2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frank ocean la la [ verse where the man me but right, i\\'m\\'t i\\'t, - there, no this \"\\'\\' t,,\\'s the a broke the i\\'t and i\\'t go, what\\'t like a see, to the tryin\\'t it\\'t us']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.decode(x) for x in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142be301-c5c0-4074-995c-5f3e2d10f8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9640e69-ba5a-4c55-afbf-21c97a1238ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72a6aa6-1728-4785-aedb-3cc6df068f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
